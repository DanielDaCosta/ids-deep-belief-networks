{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scapy.all import * \n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTC = timezone.utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Main DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting TCP Flag Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Flags Mapping\n",
    "# Check here for bitmap: https://www.noction.com/blog/tcp-flags#:~:text=The%20hexadecimal%20number%200x02%20tells,a%20particular%20flag%20is%20set.\n",
    "FIN = 0x01\n",
    "SYN = 0x02\n",
    "RST = 0x04\n",
    "PSH = 0x08\n",
    "ACK = 0x10\n",
    "URG = 0x20\n",
    "ECE = 0x40\n",
    "CWR = 0x80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make important assumption that the first flow we see in the pcap for a unique flow_id, is considered as the \"forward packet\". This may not necessarily be the packet initiated by the host (perhaps), but it is a fair assumption to make. \n",
    "\n",
    "This assumption just helps us define a direction of the flow and should not change anything major. If any flow has a lot of packets being sent from one direction (think DDoS), then this imbalance will be captured in the fwd or bwd total packets column. (should not matter which one specifically) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(INPUT_FILE):\n",
    "\n",
    "    \"\"\"Finds all unique flows based on flow id. Returns data frame with basic metrics computed for each flow. \"\"\"\n",
    "    print(\"Reading .pcap file.\")\n",
    "    packets = rdpcap(INPUT_FILE)\n",
    "    print(\"Reading .pcap file DONE.\")\n",
    "\n",
    "\n",
    "    print(\"Creating initial dataframe.\")\n",
    "    all_data = {}\n",
    "    flow_fwd_states = []\n",
    "    i = 0\n",
    "    for pkt in packets:\n",
    "    \n",
    "        if IP in pkt:\n",
    "            tmp_pack_dict = {}\n",
    "\n",
    "            tmp_pack_dict[\"sport\"] = pkt[IP].sport if hasattr(pkt[IP], \"sport\") else None\n",
    "            tmp_pack_dict[\"src_ip\"] = pkt[IP].src \n",
    "            tmp_pack_dict[\"dst_port\"] = pkt[IP].dport if hasattr(pkt[IP], \"dport\") else None\n",
    "            tmp_pack_dict[\"dst_ip\"] = pkt[IP].dst\n",
    "            flow_size = pkt.len\n",
    "\n",
    "            # Check https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml for Assigned Internet Protocol Numbers\n",
    "            tmp_pack_dict['protocol'] = pkt.proto\n",
    "\n",
    "            # Flow Unique Identifier / Flow ID \n",
    "            flow_id = frozenset([tmp_pack_dict[\"sport\"], tmp_pack_dict[\"src_ip\"], tmp_pack_dict[\"dst_port\"], tmp_pack_dict[\"dst_ip\"]])\n",
    "            # Need set representation because if there is a backward flow (with just order changed of source and destination) then it should be marked as \"seen\" previously \n",
    "            # Ordered flow id (to check if belongs to the same stream or not)\n",
    "            flow_id_ordered = (tmp_pack_dict['sport'], tmp_pack_dict['src_ip'], tmp_pack_dict['dst_port'], tmp_pack_dict['dst_ip']) # save it in order\n",
    "\n",
    "            if flow_id not in all_data: #meaning this is a new flow (from a different stream) \n",
    "                tmp_pack_dict[\"sizes\"] = [flow_size]\n",
    "                tmp_pack_dict[\"first_timestamp\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp\"] = pkt.time \n",
    "                tmp_pack_dict[\"flow_duration\"] = 0 \n",
    "                tmp_pack_dict[\"arrival_times\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Forward packets \n",
    "                tmp_pack_dict[\"total_fwd_packets\"] = 1 # To count the first instance \n",
    "                tmp_pack_dict[\"fwd_pkt_sizes\"] = [pkt.len]\n",
    "                tmp_pack_dict[\"first_timestamp_fwd\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp_fwd\"] = pkt.time \n",
    "                tmp_pack_dict[\"arrival_times_fwd\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Backward packets \n",
    "                tmp_pack_dict[\"total_bwd_packets\"] = 0 \n",
    "                tmp_pack_dict[\"bwd_pkt_sizes\"] = [] \n",
    "                tmp_pack_dict[\"first_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"last_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"arrival_times_bwd\"] = []\n",
    "\n",
    "                # Add flag counts \n",
    "                tmp_pack_dict[\"syn_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"fin_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"rst_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"psh_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ack_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"urg_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"cwr_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ece_flag_count\"] = 0\n",
    "\n",
    "                # create first time dictionary \n",
    "                all_data[flow_id] = tmp_pack_dict\n",
    "                # save the first instance of the flow as the forward trace \n",
    "                flow_fwd_states.append(flow_id_ordered)\n",
    "\n",
    "            else: # meaning either forward or backward trace (from the same flow!)\n",
    "\n",
    "                # Update the general features first \n",
    "                all_data[flow_id][\"sizes\"].append(flow_size) \n",
    "                all_data[flow_id][\"first_timestamp\"] = min(all_data[flow_id][\"first_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"last_timestamp\"] = max(all_data[flow_id][\"last_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"flow_duration\"] = all_data[flow_id][\"last_timestamp\"] - all_data[flow_id][\"first_timestamp\"]\n",
    "                all_data[flow_id][\"arrival_times\"].append(pkt.time)\n",
    "                \n",
    "\n",
    "                # Add forward packet features \n",
    "                if flow_id_ordered in flow_fwd_states: # check if forward packet and not backward \n",
    "                    all_data[flow_id][\"total_fwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"fwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_fwd\"] = min(all_data[flow_id][\"first_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_fwd\"] = max(all_data[flow_id][\"last_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_fwd\"].append(pkt.time)\n",
    "\n",
    "                else:\n",
    "                    all_data[flow_id][\"total_bwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"bwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_bwd\"] = pkt.time if all_data[flow_id][\"first_timestamp_bwd\"] == -1 else min(all_data[flow_id][\"first_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_bwd\"] = max(all_data[flow_id][\"last_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_bwd\"].append(pkt.time)\n",
    "\n",
    "            if TCP in pkt[IP]:\n",
    "                all_data[flow_id][\"syn_flag_count\"] += 1 if pkt[IP][TCP].flags & SYN else 0 \n",
    "                all_data[flow_id][\"fin_flag_count\"] += 1 if pkt[IP][TCP].flags & FIN else 0\n",
    "                all_data[flow_id][\"rst_flag_count\"] += 1 if pkt[IP][TCP].flags & RST else 0 \n",
    "                all_data[flow_id][\"psh_flag_count\"] += 1 if pkt[IP][TCP].flags & PSH else 0\n",
    "                all_data[flow_id][\"ack_flag_count\"] += 1 if pkt[IP][TCP].flags & ACK else 0 \n",
    "                all_data[flow_id][\"urg_flag_count\"] += 1 if pkt[IP][TCP].flags & URG else 0 \n",
    "                all_data[flow_id][\"cwr_flag_count\"] += 1 if pkt[IP][TCP].flags & CWR else 0\n",
    "                all_data[flow_id][\"ece_flag_count\"] += 1 if pkt[IP][TCP].flags & ECE else 0\n",
    "                \n",
    "\n",
    "    df = pd.DataFrame.from_dict(all_data, orient=\"index\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Initial data frame created.\")\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .pcap file.\n",
      "Reading .pcap file DONE.\n",
      "Creating initial dataframe.\n",
      "Initial data frame created.\n"
     ]
    }
   ],
   "source": [
    "FILE = \"DoS_Slowhttptest.pcap\"\n",
    "df = create_dataframe(INPUT_FILE=FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>protocol</th>\n",
       "      <th>sizes</th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>...</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>syn_flag_count</th>\n",
       "      <th>fin_flag_count</th>\n",
       "      <th>rst_flag_count</th>\n",
       "      <th>psh_flag_count</th>\n",
       "      <th>ack_flag_count</th>\n",
       "      <th>urg_flag_count</th>\n",
       "      <th>cwr_flag_count</th>\n",
       "      <th>ece_flag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33372</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 408, 52, 2016, 52, 52, 52, 52]</td>\n",
       "      <td>1499260537.936806</td>\n",
       "      <td>1499260537.953493</td>\n",
       "      <td>0.016687</td>\n",
       "      <td>[1499260537.936806, 1499260537.936937, 1499260...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499260537.952963</td>\n",
       "      <td>[1499260537.936937, 1499260537.942500, 1499260...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33374</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 572, 52, 57, 52, 63, 52, 52, 2035...</td>\n",
       "      <td>1499260537.936810</td>\n",
       "      <td>1499260778.938966</td>\n",
       "      <td>241.002156</td>\n",
       "      <td>[1499260537.936810, 1499260537.936960, 1499260...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499260778.935015</td>\n",
       "      <td>[1499260537.936960, 1499260537.942545, 1499260...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33376</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 572, 52, 63, 52, 68, 52, 52, 2035...</td>\n",
       "      <td>1499260537.942399</td>\n",
       "      <td>1499260778.938965</td>\n",
       "      <td>240.996566</td>\n",
       "      <td>[1499260537.942399, 1499260537.942445, 1499260...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499260778.934712</td>\n",
       "      <td>[1499260537.942445, 1499260537.947836, 1499260...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33378</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 572, 52, 67, 52, 64, 52, 52, 1500...</td>\n",
       "      <td>1499260537.947433</td>\n",
       "      <td>1499260778.938966</td>\n",
       "      <td>240.991533</td>\n",
       "      <td>[1499260537.947433, 1499260537.947521, 1499260...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499260778.936075</td>\n",
       "      <td>[1499260537.947521, 1499260537.952938, 1499260...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33380</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 572, 52, 62, 52, 69, 52, 52, 2035...</td>\n",
       "      <td>1499260537.952833</td>\n",
       "      <td>1499260778.939013</td>\n",
       "      <td>240.986180</td>\n",
       "      <td>[1499260537.952833, 1499260537.952920, 1499260...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499260778.937456</td>\n",
       "      <td>[1499260537.952920, 1499260537.958136, 1499260...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sport      src_ip  dst_port         dst_ip  protocol  \\\n",
       "0  33372  172.16.0.1        80  192.168.10.50         6   \n",
       "1  33374  172.16.0.1        80  192.168.10.50         6   \n",
       "2  33376  172.16.0.1        80  192.168.10.50         6   \n",
       "3  33378  172.16.0.1        80  192.168.10.50         6   \n",
       "4  33380  172.16.0.1        80  192.168.10.50         6   \n",
       "\n",
       "                                               sizes    first_timestamp  \\\n",
       "0        [60, 60, 52, 408, 52, 2016, 52, 52, 52, 52]  1499260537.936806   \n",
       "1  [60, 60, 52, 572, 52, 57, 52, 63, 52, 52, 2035...  1499260537.936810   \n",
       "2  [60, 60, 52, 572, 52, 63, 52, 68, 52, 52, 2035...  1499260537.942399   \n",
       "3  [60, 60, 52, 572, 52, 67, 52, 64, 52, 52, 1500...  1499260537.947433   \n",
       "4  [60, 60, 52, 572, 52, 62, 52, 69, 52, 52, 2035...  1499260537.952833   \n",
       "\n",
       "      last_timestamp flow_duration  \\\n",
       "0  1499260537.953493      0.016687   \n",
       "1  1499260778.938966    241.002156   \n",
       "2  1499260778.938965    240.996566   \n",
       "3  1499260778.938966    240.991533   \n",
       "4  1499260778.939013    240.986180   \n",
       "\n",
       "                                       arrival_times  ...  last_timestamp_bwd  \\\n",
       "0  [1499260537.936806, 1499260537.936937, 1499260...  ...   1499260537.952963   \n",
       "1  [1499260537.936810, 1499260537.936960, 1499260...  ...   1499260778.935015   \n",
       "2  [1499260537.942399, 1499260537.942445, 1499260...  ...   1499260778.934712   \n",
       "3  [1499260537.947433, 1499260537.947521, 1499260...  ...   1499260778.936075   \n",
       "4  [1499260537.952833, 1499260537.952920, 1499260...  ...   1499260778.937456   \n",
       "\n",
       "                                   arrival_times_bwd syn_flag_count  \\\n",
       "0  [1499260537.936937, 1499260537.942500, 1499260...              2   \n",
       "1  [1499260537.936960, 1499260537.942545, 1499260...              2   \n",
       "2  [1499260537.942445, 1499260537.947836, 1499260...              2   \n",
       "3  [1499260537.947521, 1499260537.952938, 1499260...              2   \n",
       "4  [1499260537.952920, 1499260537.958136, 1499260...              2   \n",
       "\n",
       "  fin_flag_count rst_flag_count  psh_flag_count ack_flag_count urg_flag_count  \\\n",
       "0              2              0               2              9              0   \n",
       "1              2              1               4             11              0   \n",
       "2              2              1               4             11              0   \n",
       "3              2              1               4             12              0   \n",
       "4              2              1               4             11              0   \n",
       "\n",
       "  cwr_flag_count ece_flag_count  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running sanity check to make sure there are no duplicates based on flow_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\"]\n",
    "duplicates = df.duplicated(subset=subset_cols)\n",
    "\n",
    "duplicate_rows = df[duplicates]\n",
    "assert duplicate_rows.shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any first_timestamp_fwd == -1\n",
    "first_fwd_timestamp = df[df.loc[:, \"first_timestamp_fwd\"] == -1]\n",
    "assert first_fwd_timestamp.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change to NaN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heryani/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/heryani/.local/lib/python3.8/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "## Overall\n",
    "df[\"total_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "\n",
    "## Forward\n",
    "df[\"total_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "## Backward\n",
    "df[\"total_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.std(x)),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>total_bwd_pkt_size</th>\n",
       "      <th>avg_bwd_pkt_size</th>\n",
       "      <th>std_bwd_pkt_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_timestamp_bwd last_timestamp_bwd arrival_times_bwd  \\\n",
       "149                   -1                 -1                []   \n",
       "150                   -1                 -1                []   \n",
       "151                   -1                 -1                []   \n",
       "152                   -1                 -1                []   \n",
       "153                   -1                 -1                []   \n",
       "...                  ...                ...               ...   \n",
       "4192                  -1                 -1                []   \n",
       "4193                  -1                 -1                []   \n",
       "4194                  -1                 -1                []   \n",
       "4195                  -1                 -1                []   \n",
       "4205                  -1                 -1                []   \n",
       "\n",
       "      total_bwd_pkt_size  avg_bwd_pkt_size  std_bwd_pkt_size  \n",
       "149                  0.0               NaN               NaN  \n",
       "150                  0.0               NaN               NaN  \n",
       "151                  0.0               NaN               NaN  \n",
       "152                  0.0               NaN               NaN  \n",
       "153                  0.0               NaN               NaN  \n",
       "...                  ...               ...               ...  \n",
       "4192                 0.0               NaN               NaN  \n",
       "4193                 0.0               NaN               NaN  \n",
       "4194                 0.0               NaN               NaN  \n",
       "4195                 0.0               NaN               NaN  \n",
       "4205                 0.0               NaN               NaN  \n",
       "\n",
       "[2804 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cases when first_timestamp_bwd == -1 => last_timestamp_bwd has to be -1 as well. Also, we should perhaps change total_bwd_pkt_size to NaN in this case too!\n",
    "first_bwd_timestamp = df[df.loc[:, \"first_timestamp_bwd\"] == -1]\n",
    "first_bwd_timestamp.loc[:, [\"first_timestamp_bwd\", \"last_timestamp_bwd\", \"arrival_times_bwd\", \"total_bwd_pkt_size\", \"avg_bwd_pkt_size\", \"std_bwd_pkt_size\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BWD timestamps conversion\n",
    "\n",
    "Convert -1 values to np.nan for better readability when converting to human-readable formats ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd_cols = [\"first_timestamp_bwd\", \"last_timestamp_bwd\"]\n",
    "df[bwd_cols] = df[bwd_cols].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport                  False\n",
       "src_ip                 False\n",
       "dst_port               False\n",
       "dst_ip                 False\n",
       "protocol               False\n",
       "sizes                  False\n",
       "first_timestamp        False\n",
       "last_timestamp         False\n",
       "flow_duration          False\n",
       "arrival_times          False\n",
       "total_fwd_packets      False\n",
       "fwd_pkt_sizes          False\n",
       "first_timestamp_fwd    False\n",
       "last_timestamp_fwd     False\n",
       "arrival_times_fwd      False\n",
       "total_bwd_packets      False\n",
       "bwd_pkt_sizes          False\n",
       "first_timestamp_bwd    False\n",
       "last_timestamp_bwd     False\n",
       "arrival_times_bwd      False\n",
       "syn_flag_count         False\n",
       "fin_flag_count         False\n",
       "rst_flag_count         False\n",
       "psh_flag_count         False\n",
       "ack_flag_count         False\n",
       "urg_flag_count         False\n",
       "cwr_flag_count         False\n",
       "ece_flag_count         False\n",
       "total_size             False\n",
       "avg_size               False\n",
       "std_size               False\n",
       "total_fwd_pkt_size     False\n",
       "avg_fwd_pkt_size       False\n",
       "std_fwd_pkt_size       False\n",
       "total_bwd_pkt_size     False\n",
       "avg_bwd_pkt_size       False\n",
       "std_bwd_pkt_size       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.eq(-1).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing flow durations\n",
    "\n",
    "NOTE: Flow durations are in SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499260537.936806</td>\n",
       "      <td>1499260537.953493</td>\n",
       "      <td>0.016687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499260537.936810</td>\n",
       "      <td>1499260778.938966</td>\n",
       "      <td>241.002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499260537.942399</td>\n",
       "      <td>1499260778.938965</td>\n",
       "      <td>240.996566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1499260537.947433</td>\n",
       "      <td>1499260778.938966</td>\n",
       "      <td>240.991533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1499260537.952833</td>\n",
       "      <td>1499260778.939013</td>\n",
       "      <td>240.986180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>1499261701.007715</td>\n",
       "      <td>1499261726.660328</td>\n",
       "      <td>25.652613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>1499261707.017783</td>\n",
       "      <td>1499261719.844475</td>\n",
       "      <td>12.826692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>1499261712.764782</td>\n",
       "      <td>1499261725.604725</td>\n",
       "      <td>12.839943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>1499261715.765309</td>\n",
       "      <td>1499261722.180457</td>\n",
       "      <td>6.415148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>1499261718.764958</td>\n",
       "      <td>1499261719.568185</td>\n",
       "      <td>0.803227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4217 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        first_timestamp     last_timestamp flow_duration\n",
       "0     1499260537.936806  1499260537.953493      0.016687\n",
       "1     1499260537.936810  1499260778.938966    241.002156\n",
       "2     1499260537.942399  1499260778.938965    240.996566\n",
       "3     1499260537.947433  1499260778.938966    240.991533\n",
       "4     1499260537.952833  1499260778.939013    240.986180\n",
       "...                 ...                ...           ...\n",
       "4212  1499261701.007715  1499261726.660328     25.652613\n",
       "4213  1499261707.017783  1499261719.844475     12.826692\n",
       "4214  1499261712.764782  1499261725.604725     12.839943\n",
       "4215  1499261715.765309  1499261722.180457      6.415148\n",
       "4216  1499261718.764958  1499261719.568185      0.803227\n",
       "\n",
       "[4217 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fwd_flow_duration\"] = df.loc[:, \"last_timestamp_fwd\"] - df.loc[:, \"first_timestamp_fwd\"]\n",
    "df[\"bwd_flow_duration\"] = df.loc[:, \"last_timestamp_bwd\"] - df.loc[:, \"first_timestamp_bwd\"]\n",
    "df[\"flow_duration\"] = df.loc[:, \"last_timestamp\"] - df.loc[:, \"first_timestamp\"]\n",
    "df.loc[:, [\"first_timestamp\", \"last_timestamp\", \"flow_duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens to bwd_flow_duration when timestamps were -1.\n",
    "Sanity check to make sure it is also NaN to differentiate from case where there was exactly one bwd packet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[df.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, \"bwd_flow_duration\"].isna().all() == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: flow_duration will be 0 if only one packet was sent (overall, fwd or bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case when fwd_flow_duration is 0. total_fwd_packets should be 1 \n",
    "zero_fwd_flow_duration = df[df.loc[:, \"fwd_flow_duration\"] == 0]\n",
    "assert zero_fwd_flow_duration.shape[0] == zero_fwd_flow_duration.loc[:, \"total_fwd_packets\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are cases when flow_duration is > 0 but both bwd_flow_duration and fwd_flow_duration = 0. These are cases where at most one forward and backward packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_fwd_packets</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_flow_duration</th>\n",
       "      <th>bwd_flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [total_fwd_packets, total_bwd_packets, flow_duration, fwd_flow_duration, bwd_flow_duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for this case as well \n",
    "mismatched_durations = df[(df.loc[:, \"flow_duration\"] > 0) & (df.loc[:, \"fwd_flow_duration\"] == 0) & (df.loc[:, \"bwd_flow_duration\"] == 0)]\n",
    "mismatched_durations.loc[:, [\"total_fwd_packets\", \"total_bwd_packets\", \"flow_duration\", \"fwd_flow_duration\", \"bwd_flow_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make these assertions for checking\n",
    "if mismatched_durations.shape[0] > 0:\n",
    "    assert mismatched_durations.loc[:, \"total_fwd_packets\"].max() == 1\n",
    "    assert mismatched_durations.loc[:, \"total_bwd_packets\"].max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting timestamps to human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "\n",
    "# Overall\n",
    "df_test.loc[:, \"first_timestamp\"] = df.loc[:, \"first_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp\"] = df.loc[:, \"last_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Forward \n",
    "df_test.loc[:, \"first_timestamp_fwd\"] = df.loc[:, \"first_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp_fwd\"] = df.loc[:, \"last_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Backward \n",
    "df_test.loc[:, \"first_timestamp_bwd_new\"] = df.loc[:, \"first_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)\n",
    "df_test.loc[:, \"last_timestamp_bwd_new\"] = df.loc[:, \"last_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to make sure timestamp conversion preserves NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd_new</th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_timestamp_bwd_new first_timestamp_bwd\n",
       "149                     NaN                 NaN\n",
       "150                     NaN                 NaN\n",
       "151                     NaN                 NaN\n",
       "152                     NaN                 NaN\n",
       "153                     NaN                 NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, [\"first_timestamp_bwd_new\", \"first_timestamp_bwd\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing inter-arrival times and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_time = df_test.copy()\n",
    "def find_diff(arrival_times):\n",
    "    return [float(arrival_times[i+1] - arrival_times[i]) for i in range(len(arrival_times)-1)]\n",
    "\n",
    "# Overall \n",
    "df_time.loc[:, \"inter_arrival_times\"] = df_time.loc[:, \"arrival_times\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean\"] = df_time.loc[:, \"inter_arrival_times\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std\"] = df_time.loc[: ,\"inter_arrival_times\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Forward\n",
    "df_time.loc[:, \"inter_arrival_times_fwd\"] = df_time.loc[:, \"arrival_times_fwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_fwd\"] = df_time.loc[:, \"inter_arrival_times_fwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_fwd\"] = df_time.loc[: ,\"inter_arrival_times_fwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Backward\n",
    "df_time.loc[:, \"inter_arrival_times_bwd\"] = df_time.loc[:, \"arrival_times_bwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_bwd\"] = df_time.loc[:, \"inter_arrival_times_bwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_bwd\"] = df_time.loc[: ,\"inter_arrival_times_bwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# df_time[df_time.loc[:, \"arrival_times\"].apply(lambda x: len(x) == 1)].loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>inter_arrival_times</th>\n",
       "      <th>inter_arrival_mean</th>\n",
       "      <th>inter_arrival_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1499260537.936806, 1499260537.936937, 1499260...</td>\n",
       "      <td>[0.000131, 0.001328, 0.004162, 7.3e-05, 0.0042...</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1499260537.936810, 1499260537.936960, 1499260...</td>\n",
       "      <td>[0.00015, 0.00131, 0.004147, 0.000128, 109.993...</td>\n",
       "      <td>20.083513</td>\n",
       "      <td>40.619216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1499260537.942399, 1499260537.942445, 1499260...</td>\n",
       "      <td>[4.6e-05, 0.000627, 0.004707, 5.7e-05, 109.987...</td>\n",
       "      <td>20.083047</td>\n",
       "      <td>40.618250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1499260537.947433, 1499260537.947521, 1499260...</td>\n",
       "      <td>[8.8e-05, 0.000767, 0.004567, 8.3e-05, 109.982...</td>\n",
       "      <td>18.537810</td>\n",
       "      <td>39.389053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1499260537.952833, 1499260537.952920, 1499260...</td>\n",
       "      <td>[8.7e-05, 0.000554, 0.004594, 6.8e-05, 109.977...</td>\n",
       "      <td>20.082182</td>\n",
       "      <td>40.616362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>[1499261701.007715, 1499261701.007825, 1499261...</td>\n",
       "      <td>[0.00011, 0.000571, 0.000382, 0.196487, 0.2000...</td>\n",
       "      <td>1.710174</td>\n",
       "      <td>3.416007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>[1499261707.017783, 1499261707.017876, 1499261...</td>\n",
       "      <td>[9.3e-05, 0.000784, 4e-06, 0.198357, 0.200179,...</td>\n",
       "      <td>0.916192</td>\n",
       "      <td>1.743787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>[1499261712.764782, 1499261712.764936, 1499261...</td>\n",
       "      <td>[0.000154, 0.000532, 0.000305, 0.199182, 0.200...</td>\n",
       "      <td>0.917139</td>\n",
       "      <td>1.745689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>[1499261715.765309, 1499261715.765426, 1499261...</td>\n",
       "      <td>[0.000117, 0.000714, 4.9e-05, 0.198735, 0.1999...</td>\n",
       "      <td>0.493473</td>\n",
       "      <td>0.877334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>[1499261718.764958, 1499261718.765013, 1499261...</td>\n",
       "      <td>[5.5e-05, 0.000771, 3e-06, 0.19929, 0.199987, ...</td>\n",
       "      <td>0.080323</td>\n",
       "      <td>0.109185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4217 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          arrival_times  \\\n",
       "0     [1499260537.936806, 1499260537.936937, 1499260...   \n",
       "1     [1499260537.936810, 1499260537.936960, 1499260...   \n",
       "2     [1499260537.942399, 1499260537.942445, 1499260...   \n",
       "3     [1499260537.947433, 1499260537.947521, 1499260...   \n",
       "4     [1499260537.952833, 1499260537.952920, 1499260...   \n",
       "...                                                 ...   \n",
       "4212  [1499261701.007715, 1499261701.007825, 1499261...   \n",
       "4213  [1499261707.017783, 1499261707.017876, 1499261...   \n",
       "4214  [1499261712.764782, 1499261712.764936, 1499261...   \n",
       "4215  [1499261715.765309, 1499261715.765426, 1499261...   \n",
       "4216  [1499261718.764958, 1499261718.765013, 1499261...   \n",
       "\n",
       "                                    inter_arrival_times  inter_arrival_mean  \\\n",
       "0     [0.000131, 0.001328, 0.004162, 7.3e-05, 0.0042...            0.001854   \n",
       "1     [0.00015, 0.00131, 0.004147, 0.000128, 109.993...           20.083513   \n",
       "2     [4.6e-05, 0.000627, 0.004707, 5.7e-05, 109.987...           20.083047   \n",
       "3     [8.8e-05, 0.000767, 0.004567, 8.3e-05, 109.982...           18.537810   \n",
       "4     [8.7e-05, 0.000554, 0.004594, 6.8e-05, 109.977...           20.082182   \n",
       "...                                                 ...                 ...   \n",
       "4212  [0.00011, 0.000571, 0.000382, 0.196487, 0.2000...            1.710174   \n",
       "4213  [9.3e-05, 0.000784, 4e-06, 0.198357, 0.200179,...            0.916192   \n",
       "4214  [0.000154, 0.000532, 0.000305, 0.199182, 0.200...            0.917139   \n",
       "4215  [0.000117, 0.000714, 4.9e-05, 0.198735, 0.1999...            0.493473   \n",
       "4216  [5.5e-05, 0.000771, 3e-06, 0.19929, 0.199987, ...            0.080323   \n",
       "\n",
       "      inter_arrival_std  \n",
       "0              0.002004  \n",
       "1             40.619216  \n",
       "2             40.618250  \n",
       "3             39.389053  \n",
       "4             40.616362  \n",
       "...                 ...  \n",
       "4212           3.416007  \n",
       "4213           1.743787  \n",
       "4214           1.745689  \n",
       "4215           0.877334  \n",
       "4216           0.109185  \n",
       "\n",
       "[4217 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration',\n",
       "       'first_timestamp_bwd_new', 'last_timestamp_bwd_new',\n",
       "       'inter_arrival_times', 'inter_arrival_mean', 'inter_arrival_std',\n",
       "       'inter_arrival_times_fwd', 'inter_arrival_mean_fwd',\n",
       "       'inter_arrival_std_fwd', 'inter_arrival_times_bwd',\n",
       "       'inter_arrival_mean_bwd', 'inter_arrival_std_bwd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_features = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\", \"protocol\"]\n",
    "overall_features = [\"first_timestamp\", \"last_timestamp\", \"flow_duration\", \"total_size\", \"avg_size\", \"std_size\", \"inter_arrival_mean\", \"inter_arrival_std\"]\n",
    "fwd_features = [\"total_fwd_packets\", \"first_timestamp_fwd\", \"last_timestamp_fwd\", \"fwd_flow_duration\", \"total_fwd_pkt_size\", \"avg_fwd_pkt_size\", \"std_fwd_pkt_size\", \"inter_arrival_mean_fwd\", \"inter_arrival_std_fwd\"]\n",
    "bwd_features = ['total_bwd_packets', 'first_timestamp_bwd', 'last_timestamp_bwd', 'bwd_flow_duration', 'total_bwd_pkt_size', 'avg_bwd_pkt_size', 'std_bwd_pkt_size', 'inter_arrival_mean_bwd', 'inter_arrival_std_bwd']\n",
    "flag_features = ['syn_flag_count', 'fin_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count','cwr_flag_count', 'ece_flag_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features kept: 39\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = general_features + overall_features + fwd_features + bwd_features + flag_features\n",
    "print(f\"Total features kept: {len(features_to_keep)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching label for model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_time.copy()\n",
    "df_final = df_final[features_to_keep]\n",
    "df_final.loc[:, \"label\"] = \"dos_slowhttptest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"dos_slowhttptest.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
