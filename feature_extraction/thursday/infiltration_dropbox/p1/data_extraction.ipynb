{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scapy.all import * \n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTC = timezone.utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Main DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting TCP Flag Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Flags Mapping\n",
    "# Check here for bitmap: https://www.noction.com/blog/tcp-flags#:~:text=The%20hexadecimal%20number%200x02%20tells,a%20particular%20flag%20is%20set.\n",
    "FIN = 0x01\n",
    "SYN = 0x02\n",
    "RST = 0x04\n",
    "PSH = 0x08\n",
    "ACK = 0x10\n",
    "URG = 0x20\n",
    "ECE = 0x40\n",
    "CWR = 0x80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make important assumption that the first flow we see in the pcap for a unique flow_id, is considered as the \"forward packet\". This may not necessarily be the packet initiated by the host (perhaps), but it is a fair assumption to make. \n",
    "\n",
    "This assumption just helps us define a direction of the flow and should not change anything major. If any flow has a lot of packets being sent from one direction (think DDoS), then this imbalance will be captured in the fwd or bwd total packets column. (should not matter which one specifically) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(INPUT_FILE):\n",
    "\n",
    "    \"\"\"Finds all unique flows based on flow id. Returns data frame with basic metrics computed for each flow. \"\"\"\n",
    "    print(\"Reading .pcap file.\")\n",
    "    packets = rdpcap(INPUT_FILE)\n",
    "    print(\"Reading .pcap file DONE.\")\n",
    "\n",
    "\n",
    "    print(\"Creating initial dataframe.\")\n",
    "    all_data = {}\n",
    "    flow_fwd_states = []\n",
    "    i = 0\n",
    "    for pkt in packets:\n",
    "    \n",
    "        if IP in pkt:\n",
    "            tmp_pack_dict = {}\n",
    "\n",
    "            tmp_pack_dict[\"sport\"] = pkt[IP].sport if hasattr(pkt[IP], \"sport\") else None\n",
    "            tmp_pack_dict[\"src_ip\"] = pkt[IP].src \n",
    "            tmp_pack_dict[\"dst_port\"] = pkt[IP].dport if hasattr(pkt[IP], \"dport\") else None\n",
    "            tmp_pack_dict[\"dst_ip\"] = pkt[IP].dst\n",
    "            flow_size = pkt.len\n",
    "\n",
    "            # Check https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml for Assigned Internet Protocol Numbers\n",
    "            tmp_pack_dict['protocol'] = pkt.proto\n",
    "\n",
    "            # Flow Unique Identifier / Flow ID \n",
    "            flow_id = frozenset([tmp_pack_dict[\"sport\"], tmp_pack_dict[\"src_ip\"], tmp_pack_dict[\"dst_port\"], tmp_pack_dict[\"dst_ip\"]])\n",
    "            # Need set representation because if there is a backward flow (with just order changed of source and destination) then it should be marked as \"seen\" previously \n",
    "            # Ordered flow id (to check if belongs to the same stream or not)\n",
    "            flow_id_ordered = (tmp_pack_dict['sport'], tmp_pack_dict['src_ip'], tmp_pack_dict['dst_port'], tmp_pack_dict['dst_ip']) # save it in order\n",
    "\n",
    "            if flow_id not in all_data: #meaning this is a new flow (from a different stream) \n",
    "                tmp_pack_dict[\"sizes\"] = [flow_size]\n",
    "                tmp_pack_dict[\"first_timestamp\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp\"] = pkt.time \n",
    "                tmp_pack_dict[\"flow_duration\"] = 0 \n",
    "                tmp_pack_dict[\"arrival_times\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Forward packets \n",
    "                tmp_pack_dict[\"total_fwd_packets\"] = 1 # To count the first instance \n",
    "                tmp_pack_dict[\"fwd_pkt_sizes\"] = [pkt.len]\n",
    "                tmp_pack_dict[\"first_timestamp_fwd\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp_fwd\"] = pkt.time \n",
    "                tmp_pack_dict[\"arrival_times_fwd\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Backward packets \n",
    "                tmp_pack_dict[\"total_bwd_packets\"] = 0 \n",
    "                tmp_pack_dict[\"bwd_pkt_sizes\"] = [] \n",
    "                tmp_pack_dict[\"first_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"last_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"arrival_times_bwd\"] = []\n",
    "\n",
    "                # Add flag counts \n",
    "                tmp_pack_dict[\"syn_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"fin_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"rst_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"psh_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ack_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"urg_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"cwr_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ece_flag_count\"] = 0\n",
    "\n",
    "                # create first time dictionary \n",
    "                all_data[flow_id] = tmp_pack_dict\n",
    "                # save the first instance of the flow as the forward trace \n",
    "                flow_fwd_states.append(flow_id_ordered)\n",
    "\n",
    "            else: # meaning either forward or backward trace (from the same flow!)\n",
    "\n",
    "                # Update the general features first \n",
    "                all_data[flow_id][\"sizes\"].append(flow_size) \n",
    "                all_data[flow_id][\"first_timestamp\"] = min(all_data[flow_id][\"first_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"last_timestamp\"] = max(all_data[flow_id][\"last_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"flow_duration\"] = all_data[flow_id][\"last_timestamp\"] - all_data[flow_id][\"first_timestamp\"]\n",
    "                all_data[flow_id][\"arrival_times\"].append(pkt.time)\n",
    "                \n",
    "\n",
    "                # Add forward packet features \n",
    "                if flow_id_ordered in flow_fwd_states: # check if forward packet and not backward \n",
    "                    all_data[flow_id][\"total_fwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"fwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_fwd\"] = min(all_data[flow_id][\"first_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_fwd\"] = max(all_data[flow_id][\"last_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_fwd\"].append(pkt.time)\n",
    "\n",
    "                else:\n",
    "                    all_data[flow_id][\"total_bwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"bwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_bwd\"] = pkt.time if all_data[flow_id][\"first_timestamp_bwd\"] == -1 else min(all_data[flow_id][\"first_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_bwd\"] = max(all_data[flow_id][\"last_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_bwd\"].append(pkt.time)\n",
    "\n",
    "            if TCP in pkt[IP]:\n",
    "                all_data[flow_id][\"syn_flag_count\"] += 1 if pkt[IP][TCP].flags & SYN else 0 \n",
    "                all_data[flow_id][\"fin_flag_count\"] += 1 if pkt[IP][TCP].flags & FIN else 0\n",
    "                all_data[flow_id][\"rst_flag_count\"] += 1 if pkt[IP][TCP].flags & RST else 0 \n",
    "                all_data[flow_id][\"psh_flag_count\"] += 1 if pkt[IP][TCP].flags & PSH else 0\n",
    "                all_data[flow_id][\"ack_flag_count\"] += 1 if pkt[IP][TCP].flags & ACK else 0 \n",
    "                all_data[flow_id][\"urg_flag_count\"] += 1 if pkt[IP][TCP].flags & URG else 0 \n",
    "                all_data[flow_id][\"cwr_flag_count\"] += 1 if pkt[IP][TCP].flags & CWR else 0\n",
    "                all_data[flow_id][\"ece_flag_count\"] += 1 if pkt[IP][TCP].flags & ECE else 0\n",
    "                \n",
    "\n",
    "    df = pd.DataFrame.from_dict(all_data, orient=\"index\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Initial data frame created.\")\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .pcap file.\n",
      "Reading .pcap file DONE.\n",
      "Creating initial dataframe.\n",
      "Initial data frame created.\n"
     ]
    }
   ],
   "source": [
    "FILE = \"Infiltration_Dropbox_P1_WinVista.pcap\"\n",
    "df = create_dataframe(INPUT_FILE=FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>protocol</th>\n",
       "      <th>sizes</th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>...</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>syn_flag_count</th>\n",
       "      <th>fin_flag_count</th>\n",
       "      <th>rst_flag_count</th>\n",
       "      <th>psh_flag_count</th>\n",
       "      <th>ack_flag_count</th>\n",
       "      <th>urg_flag_count</th>\n",
       "      <th>cwr_flag_count</th>\n",
       "      <th>ece_flag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1260</td>\n",
       "      <td>192.168.10.8</td>\n",
       "      <td>444</td>\n",
       "      <td>205.174.165.73</td>\n",
       "      <td>6</td>\n",
       "      <td>[52, 52, 40, 44, 40, 307, 76, 40, 133, 40, 44,...</td>\n",
       "      <td>1499364265.514724</td>\n",
       "      <td>1499366665.586962</td>\n",
       "      <td>2400.072238</td>\n",
       "      <td>[1499364265.514724, 1499364265.515214, 1499364...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499366665.586962</td>\n",
       "      <td>[1499364265.515214, 1499364265.659476, 1499364...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sport        src_ip  dst_port          dst_ip  protocol  \\\n",
       "0   1260  192.168.10.8       444  205.174.165.73         6   \n",
       "\n",
       "                                               sizes    first_timestamp  \\\n",
       "0  [52, 52, 40, 44, 40, 307, 76, 40, 133, 40, 44,...  1499364265.514724   \n",
       "\n",
       "      last_timestamp flow_duration  \\\n",
       "0  1499366665.586962   2400.072238   \n",
       "\n",
       "                                       arrival_times  ...  last_timestamp_bwd  \\\n",
       "0  [1499364265.514724, 1499364265.515214, 1499364...  ...   1499366665.586962   \n",
       "\n",
       "                                   arrival_times_bwd syn_flag_count  \\\n",
       "0  [1499364265.515214, 1499364265.659476, 1499364...              2   \n",
       "\n",
       "  fin_flag_count rst_flag_count  psh_flag_count ack_flag_count urg_flag_count  \\\n",
       "0              0              0             424            838              0   \n",
       "\n",
       "  cwr_flag_count ece_flag_count  \n",
       "0              0              0  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running sanity check to make sure there are no duplicates based on flow_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\"]\n",
    "duplicates = df.duplicated(subset=subset_cols)\n",
    "\n",
    "duplicate_rows = df[duplicates]\n",
    "assert duplicate_rows.shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any first_timestamp_fwd == -1\n",
    "first_fwd_timestamp = df[df.loc[:, \"first_timestamp_fwd\"] == -1]\n",
    "assert first_fwd_timestamp.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change to NaN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overall\n",
    "df[\"total_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "\n",
    "## Forward\n",
    "df[\"total_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "## Backward\n",
    "df[\"total_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.std(x)),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>total_bwd_pkt_size</th>\n",
       "      <th>avg_bwd_pkt_size</th>\n",
       "      <th>std_bwd_pkt_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_timestamp_bwd, last_timestamp_bwd, arrival_times_bwd, total_bwd_pkt_size, avg_bwd_pkt_size, std_bwd_pkt_size]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cases when first_timestamp_bwd == -1 => last_timestamp_bwd has to be -1 as well. Also, we should perhaps change total_bwd_pkt_size to NaN in this case too!\n",
    "first_bwd_timestamp = df[df.loc[:, \"first_timestamp_bwd\"] == -1]\n",
    "first_bwd_timestamp.loc[:, [\"first_timestamp_bwd\", \"last_timestamp_bwd\", \"arrival_times_bwd\", \"total_bwd_pkt_size\", \"avg_bwd_pkt_size\", \"std_bwd_pkt_size\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BWD timestamps conversion\n",
    "\n",
    "Convert -1 values to np.nan for better readability when converting to human-readable formats ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd_cols = [\"first_timestamp_bwd\", \"last_timestamp_bwd\"]\n",
    "df[bwd_cols] = df[bwd_cols].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport                  False\n",
       "src_ip                 False\n",
       "dst_port               False\n",
       "dst_ip                 False\n",
       "protocol               False\n",
       "sizes                  False\n",
       "first_timestamp        False\n",
       "last_timestamp         False\n",
       "flow_duration          False\n",
       "arrival_times          False\n",
       "total_fwd_packets      False\n",
       "fwd_pkt_sizes          False\n",
       "first_timestamp_fwd    False\n",
       "last_timestamp_fwd     False\n",
       "arrival_times_fwd      False\n",
       "total_bwd_packets      False\n",
       "bwd_pkt_sizes          False\n",
       "first_timestamp_bwd    False\n",
       "last_timestamp_bwd     False\n",
       "arrival_times_bwd      False\n",
       "syn_flag_count         False\n",
       "fin_flag_count         False\n",
       "rst_flag_count         False\n",
       "psh_flag_count         False\n",
       "ack_flag_count         False\n",
       "urg_flag_count         False\n",
       "cwr_flag_count         False\n",
       "ece_flag_count         False\n",
       "total_size             False\n",
       "avg_size               False\n",
       "std_size               False\n",
       "total_fwd_pkt_size     False\n",
       "avg_fwd_pkt_size       False\n",
       "std_fwd_pkt_size       False\n",
       "total_bwd_pkt_size     False\n",
       "avg_bwd_pkt_size       False\n",
       "std_bwd_pkt_size       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.eq(-1).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing flow durations\n",
    "\n",
    "NOTE: Flow durations are in SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499364265.514724</td>\n",
       "      <td>1499366665.586962</td>\n",
       "      <td>2400.072238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_timestamp     last_timestamp flow_duration\n",
       "0  1499364265.514724  1499366665.586962   2400.072238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fwd_flow_duration\"] = df.loc[:, \"last_timestamp_fwd\"] - df.loc[:, \"first_timestamp_fwd\"]\n",
    "df[\"bwd_flow_duration\"] = df.loc[:, \"last_timestamp_bwd\"] - df.loc[:, \"first_timestamp_bwd\"]\n",
    "df[\"flow_duration\"] = df.loc[:, \"last_timestamp\"] - df.loc[:, \"first_timestamp\"]\n",
    "df.loc[:, [\"first_timestamp\", \"last_timestamp\", \"flow_duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens to bwd_flow_duration when timestamps were -1.\n",
    "Sanity check to make sure it is also NaN to differentiate from case where there was exactly one bwd packet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[df.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, \"bwd_flow_duration\"].isna().all() == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: flow_duration will be 0 if only one packet was sent (overall, fwd or bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case when fwd_flow_duration is 0. total_fwd_packets should be 1 \n",
    "zero_fwd_flow_duration = df[df.loc[:, \"fwd_flow_duration\"] == 0]\n",
    "assert zero_fwd_flow_duration.shape[0] == zero_fwd_flow_duration.loc[:, \"total_fwd_packets\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are cases when flow_duration is > 0 but both bwd_flow_duration and fwd_flow_duration = 0. These are cases where at most one forward and backward packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_fwd_packets</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_flow_duration</th>\n",
       "      <th>bwd_flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [total_fwd_packets, total_bwd_packets, flow_duration, fwd_flow_duration, bwd_flow_duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for this case as well \n",
    "mismatched_durations = df[(df.loc[:, \"flow_duration\"] > 0) & (df.loc[:, \"fwd_flow_duration\"] == 0) & (df.loc[:, \"bwd_flow_duration\"] == 0)]\n",
    "mismatched_durations.loc[:, [\"total_fwd_packets\", \"total_bwd_packets\", \"flow_duration\", \"fwd_flow_duration\", \"bwd_flow_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make these assertions for checking\n",
    "if mismatched_durations.shape[0] > 0:\n",
    "    assert mismatched_durations.loc[:, \"total_fwd_packets\"].max() == 1\n",
    "    assert mismatched_durations.loc[:, \"total_bwd_packets\"].max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting timestamps to human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "\n",
    "# Overall\n",
    "df_test.loc[:, \"first_timestamp\"] = df.loc[:, \"first_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp\"] = df.loc[:, \"last_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Forward \n",
    "df_test.loc[:, \"first_timestamp_fwd\"] = df.loc[:, \"first_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp_fwd\"] = df.loc[:, \"last_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Backward \n",
    "df_test.loc[:, \"first_timestamp_bwd_new\"] = df.loc[:, \"first_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)\n",
    "df_test.loc[:, \"last_timestamp_bwd_new\"] = df.loc[:, \"last_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to make sure timestamp conversion preserves NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd_new</th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_timestamp_bwd_new, first_timestamp_bwd]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, [\"first_timestamp_bwd_new\", \"first_timestamp_bwd\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing inter-arrival times and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_time = df_test.copy()\n",
    "def find_diff(arrival_times):\n",
    "    return [float(arrival_times[i+1] - arrival_times[i]) for i in range(len(arrival_times)-1)]\n",
    "\n",
    "# Overall \n",
    "df_time.loc[:, \"inter_arrival_times\"] = df_time.loc[:, \"arrival_times\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean\"] = df_time.loc[:, \"inter_arrival_times\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std\"] = df_time.loc[: ,\"inter_arrival_times\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Forward\n",
    "df_time.loc[:, \"inter_arrival_times_fwd\"] = df_time.loc[:, \"arrival_times_fwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_fwd\"] = df_time.loc[:, \"inter_arrival_times_fwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_fwd\"] = df_time.loc[: ,\"inter_arrival_times_fwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Backward\n",
    "df_time.loc[:, \"inter_arrival_times_bwd\"] = df_time.loc[:, \"arrival_times_bwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_bwd\"] = df_time.loc[:, \"inter_arrival_times_bwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_bwd\"] = df_time.loc[: ,\"inter_arrival_times_bwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# df_time[df_time.loc[:, \"arrival_times\"].apply(lambda x: len(x) == 1)].loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>inter_arrival_times</th>\n",
       "      <th>inter_arrival_mean</th>\n",
       "      <th>inter_arrival_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1499364265.514724, 1499364265.515214, 1499364...</td>\n",
       "      <td>[0.00049, 7.1e-05, 0.144191, 0.194655, 0.00034...</td>\n",
       "      <td>2.864048</td>\n",
       "      <td>13.371225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       arrival_times  \\\n",
       "0  [1499364265.514724, 1499364265.515214, 1499364...   \n",
       "\n",
       "                                 inter_arrival_times  inter_arrival_mean  \\\n",
       "0  [0.00049, 7.1e-05, 0.144191, 0.194655, 0.00034...            2.864048   \n",
       "\n",
       "   inter_arrival_std  \n",
       "0          13.371225  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration',\n",
       "       'first_timestamp_bwd_new', 'last_timestamp_bwd_new',\n",
       "       'inter_arrival_times', 'inter_arrival_mean', 'inter_arrival_std',\n",
       "       'inter_arrival_times_fwd', 'inter_arrival_mean_fwd',\n",
       "       'inter_arrival_std_fwd', 'inter_arrival_times_bwd',\n",
       "       'inter_arrival_mean_bwd', 'inter_arrival_std_bwd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_features = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\", \"protocol\"]\n",
    "overall_features = [\"first_timestamp\", \"last_timestamp\", \"flow_duration\", \"total_size\", \"avg_size\", \"std_size\", \"inter_arrival_mean\", \"inter_arrival_std\"]\n",
    "fwd_features = [\"total_fwd_packets\", \"first_timestamp_fwd\", \"last_timestamp_fwd\", \"fwd_flow_duration\", \"total_fwd_pkt_size\", \"avg_fwd_pkt_size\", \"std_fwd_pkt_size\", \"inter_arrival_mean_fwd\", \"inter_arrival_std_fwd\"]\n",
    "bwd_features = ['total_bwd_packets', 'first_timestamp_bwd', 'last_timestamp_bwd', 'bwd_flow_duration', 'total_bwd_pkt_size', 'avg_bwd_pkt_size', 'std_bwd_pkt_size', 'inter_arrival_mean_bwd', 'inter_arrival_std_bwd']\n",
    "flag_features = ['syn_flag_count', 'fin_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count','cwr_flag_count', 'ece_flag_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features kept: 39\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = general_features + overall_features + fwd_features + bwd_features + flag_features\n",
    "print(f\"Total features kept: {len(features_to_keep)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching label for model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_time.copy()\n",
    "df_final = df_final[features_to_keep]\n",
    "df_final.loc[:, \"label\"] = \"infiltration_dropbox_P1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"infiltration_dropbox_P1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
