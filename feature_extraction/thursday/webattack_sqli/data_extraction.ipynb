{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scapy.all import * \n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTC = timezone.utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Main DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting TCP Flag Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Flags Mapping\n",
    "# Check here for bitmap: https://www.noction.com/blog/tcp-flags#:~:text=The%20hexadecimal%20number%200x02%20tells,a%20particular%20flag%20is%20set.\n",
    "FIN = 0x01\n",
    "SYN = 0x02\n",
    "RST = 0x04\n",
    "PSH = 0x08\n",
    "ACK = 0x10\n",
    "URG = 0x20\n",
    "ECE = 0x40\n",
    "CWR = 0x80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make important assumption that the first flow we see in the pcap for a unique flow_id, is considered as the \"forward packet\". This may not necessarily be the packet initiated by the host (perhaps), but it is a fair assumption to make. \n",
    "\n",
    "This assumption just helps us define a direction of the flow and should not change anything major. If any flow has a lot of packets being sent from one direction (think DDoS), then this imbalance will be captured in the fwd or bwd total packets column. (should not matter which one specifically) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(INPUT_FILE):\n",
    "\n",
    "    \"\"\"Finds all unique flows based on flow id. Returns data frame with basic metrics computed for each flow. \"\"\"\n",
    "    print(\"Reading .pcap file.\")\n",
    "    packets = rdpcap(INPUT_FILE)\n",
    "    print(\"Reading .pcap file DONE.\")\n",
    "\n",
    "\n",
    "    print(\"Creating initial dataframe.\")\n",
    "    all_data = {}\n",
    "    flow_fwd_states = []\n",
    "    i = 0\n",
    "    for pkt in packets:\n",
    "    \n",
    "        if IP in pkt:\n",
    "            tmp_pack_dict = {}\n",
    "\n",
    "            tmp_pack_dict[\"sport\"] = pkt[IP].sport if hasattr(pkt[IP], \"sport\") else None\n",
    "            tmp_pack_dict[\"src_ip\"] = pkt[IP].src \n",
    "            tmp_pack_dict[\"dst_port\"] = pkt[IP].dport if hasattr(pkt[IP], \"dport\") else None\n",
    "            tmp_pack_dict[\"dst_ip\"] = pkt[IP].dst\n",
    "            flow_size = pkt.len\n",
    "\n",
    "            # Check https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml for Assigned Internet Protocol Numbers\n",
    "            tmp_pack_dict['protocol'] = pkt.proto\n",
    "\n",
    "            # Flow Unique Identifier / Flow ID \n",
    "            flow_id = frozenset([tmp_pack_dict[\"sport\"], tmp_pack_dict[\"src_ip\"], tmp_pack_dict[\"dst_port\"], tmp_pack_dict[\"dst_ip\"]])\n",
    "            # Need set representation because if there is a backward flow (with just order changed of source and destination) then it should be marked as \"seen\" previously \n",
    "            # Ordered flow id (to check if belongs to the same stream or not)\n",
    "            flow_id_ordered = (tmp_pack_dict['sport'], tmp_pack_dict['src_ip'], tmp_pack_dict['dst_port'], tmp_pack_dict['dst_ip']) # save it in order\n",
    "\n",
    "            if flow_id not in all_data: #meaning this is a new flow (from a different stream) \n",
    "                tmp_pack_dict[\"sizes\"] = [flow_size]\n",
    "                tmp_pack_dict[\"first_timestamp\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp\"] = pkt.time \n",
    "                tmp_pack_dict[\"flow_duration\"] = 0 \n",
    "                tmp_pack_dict[\"arrival_times\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Forward packets \n",
    "                tmp_pack_dict[\"total_fwd_packets\"] = 1 # To count the first instance \n",
    "                tmp_pack_dict[\"fwd_pkt_sizes\"] = [pkt.len]\n",
    "                tmp_pack_dict[\"first_timestamp_fwd\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp_fwd\"] = pkt.time \n",
    "                tmp_pack_dict[\"arrival_times_fwd\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Backward packets \n",
    "                tmp_pack_dict[\"total_bwd_packets\"] = 0 \n",
    "                tmp_pack_dict[\"bwd_pkt_sizes\"] = [] \n",
    "                tmp_pack_dict[\"first_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"last_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"arrival_times_bwd\"] = []\n",
    "\n",
    "                # Add flag counts \n",
    "                tmp_pack_dict[\"syn_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"fin_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"rst_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"psh_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ack_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"urg_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"cwr_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ece_flag_count\"] = 0\n",
    "\n",
    "                # create first time dictionary \n",
    "                all_data[flow_id] = tmp_pack_dict\n",
    "                # save the first instance of the flow as the forward trace \n",
    "                flow_fwd_states.append(flow_id_ordered)\n",
    "\n",
    "            else: # meaning either forward or backward trace (from the same flow!)\n",
    "\n",
    "                # Update the general features first \n",
    "                all_data[flow_id][\"sizes\"].append(flow_size) \n",
    "                all_data[flow_id][\"first_timestamp\"] = min(all_data[flow_id][\"first_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"last_timestamp\"] = max(all_data[flow_id][\"last_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"flow_duration\"] = all_data[flow_id][\"last_timestamp\"] - all_data[flow_id][\"first_timestamp\"]\n",
    "                all_data[flow_id][\"arrival_times\"].append(pkt.time)\n",
    "                \n",
    "\n",
    "                # Add forward packet features \n",
    "                if flow_id_ordered in flow_fwd_states: # check if forward packet and not backward \n",
    "                    all_data[flow_id][\"total_fwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"fwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_fwd\"] = min(all_data[flow_id][\"first_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_fwd\"] = max(all_data[flow_id][\"last_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_fwd\"].append(pkt.time)\n",
    "\n",
    "                else:\n",
    "                    all_data[flow_id][\"total_bwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"bwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_bwd\"] = pkt.time if all_data[flow_id][\"first_timestamp_bwd\"] == -1 else min(all_data[flow_id][\"first_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_bwd\"] = max(all_data[flow_id][\"last_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_bwd\"].append(pkt.time)\n",
    "\n",
    "            if TCP in pkt[IP]:\n",
    "                all_data[flow_id][\"syn_flag_count\"] += 1 if pkt[IP][TCP].flags & SYN else 0 \n",
    "                all_data[flow_id][\"fin_flag_count\"] += 1 if pkt[IP][TCP].flags & FIN else 0\n",
    "                all_data[flow_id][\"rst_flag_count\"] += 1 if pkt[IP][TCP].flags & RST else 0 \n",
    "                all_data[flow_id][\"psh_flag_count\"] += 1 if pkt[IP][TCP].flags & PSH else 0\n",
    "                all_data[flow_id][\"ack_flag_count\"] += 1 if pkt[IP][TCP].flags & ACK else 0 \n",
    "                all_data[flow_id][\"urg_flag_count\"] += 1 if pkt[IP][TCP].flags & URG else 0 \n",
    "                all_data[flow_id][\"cwr_flag_count\"] += 1 if pkt[IP][TCP].flags & CWR else 0\n",
    "                all_data[flow_id][\"ece_flag_count\"] += 1 if pkt[IP][TCP].flags & ECE else 0\n",
    "                \n",
    "\n",
    "    df = pd.DataFrame.from_dict(all_data, orient=\"index\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Initial data frame created.\")\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .pcap file.\n",
      "Reading .pcap file DONE.\n",
      "Creating initial dataframe.\n",
      "Initial data frame created.\n"
     ]
    }
   ],
   "source": [
    "FILE = \"WebAttack_Sqli.pcap\"\n",
    "df = create_dataframe(INPUT_FILE=FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>protocol</th>\n",
       "      <th>sizes</th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>...</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>syn_flag_count</th>\n",
       "      <th>fin_flag_count</th>\n",
       "      <th>rst_flag_count</th>\n",
       "      <th>psh_flag_count</th>\n",
       "      <th>ack_flag_count</th>\n",
       "      <th>urg_flag_count</th>\n",
       "      <th>cwr_flag_count</th>\n",
       "      <th>ece_flag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36196</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 499, 52, 582, 52, 52, 52, 52, 52]</td>\n",
       "      <td>1499348407.419016</td>\n",
       "      <td>1499348412.425928</td>\n",
       "      <td>5.006912</td>\n",
       "      <td>[1499348407.419016, 1499348407.419147, 1499348...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499348412.425455</td>\n",
       "      <td>[1499348407.419147, 1499348407.420554, 1499348...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36198</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 512, 52, 1892, 52, 52, 52, 52]</td>\n",
       "      <td>1499348413.192475</td>\n",
       "      <td>1499348418.262971</td>\n",
       "      <td>5.070496</td>\n",
       "      <td>[1499348413.192475, 1499348413.192603, 1499348...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499348418.262971</td>\n",
       "      <td>[1499348413.192603, 1499348413.193473, 1499348...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36200</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 589, 52, 1933, 52, 52, 52, 52]</td>\n",
       "      <td>1499348422.024349</td>\n",
       "      <td>1499348427.063652</td>\n",
       "      <td>5.039303</td>\n",
       "      <td>[1499348422.024349, 1499348422.024463, 1499348...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499348427.063652</td>\n",
       "      <td>[1499348422.024463, 1499348422.025335, 1499348...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36202</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 652, 52, 4201, 52, 52, 52, 52, 52]</td>\n",
       "      <td>1499348433.464668</td>\n",
       "      <td>1499348438.551871</td>\n",
       "      <td>5.087203</td>\n",
       "      <td>[1499348433.464668, 1499348433.464810, 1499348...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499348438.551871</td>\n",
       "      <td>[1499348433.464810, 1499348433.465657, 1499348...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36204</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 651, 52, 2073, 52, 52, 52, 52]</td>\n",
       "      <td>1499348467.295664</td>\n",
       "      <td>1499348472.302394</td>\n",
       "      <td>5.006730</td>\n",
       "      <td>[1499348467.295664, 1499348467.295837, 1499348...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499348472.302394</td>\n",
       "      <td>[1499348467.295837, 1499348467.296825, 1499348...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sport      src_ip  dst_port         dst_ip  protocol  \\\n",
       "0  36196  172.16.0.1        80  192.168.10.50         6   \n",
       "1  36198  172.16.0.1        80  192.168.10.50         6   \n",
       "2  36200  172.16.0.1        80  192.168.10.50         6   \n",
       "3  36202  172.16.0.1        80  192.168.10.50         6   \n",
       "4  36204  172.16.0.1        80  192.168.10.50         6   \n",
       "\n",
       "                                             sizes    first_timestamp  \\\n",
       "0   [60, 60, 52, 499, 52, 582, 52, 52, 52, 52, 52]  1499348407.419016   \n",
       "1      [60, 60, 52, 512, 52, 1892, 52, 52, 52, 52]  1499348413.192475   \n",
       "2      [60, 60, 52, 589, 52, 1933, 52, 52, 52, 52]  1499348422.024349   \n",
       "3  [60, 60, 52, 652, 52, 4201, 52, 52, 52, 52, 52]  1499348433.464668   \n",
       "4      [60, 60, 52, 651, 52, 2073, 52, 52, 52, 52]  1499348467.295664   \n",
       "\n",
       "      last_timestamp flow_duration  \\\n",
       "0  1499348412.425928      5.006912   \n",
       "1  1499348418.262971      5.070496   \n",
       "2  1499348427.063652      5.039303   \n",
       "3  1499348438.551871      5.087203   \n",
       "4  1499348472.302394      5.006730   \n",
       "\n",
       "                                       arrival_times  ...  last_timestamp_bwd  \\\n",
       "0  [1499348407.419016, 1499348407.419147, 1499348...  ...   1499348412.425455   \n",
       "1  [1499348413.192475, 1499348413.192603, 1499348...  ...   1499348418.262971   \n",
       "2  [1499348422.024349, 1499348422.024463, 1499348...  ...   1499348427.063652   \n",
       "3  [1499348433.464668, 1499348433.464810, 1499348...  ...   1499348438.551871   \n",
       "4  [1499348467.295664, 1499348467.295837, 1499348...  ...   1499348472.302394   \n",
       "\n",
       "                                   arrival_times_bwd syn_flag_count  \\\n",
       "0  [1499348407.419147, 1499348407.420554, 1499348...              2   \n",
       "1  [1499348413.192603, 1499348413.193473, 1499348...              2   \n",
       "2  [1499348422.024463, 1499348422.025335, 1499348...              2   \n",
       "3  [1499348433.464810, 1499348433.465657, 1499348...              2   \n",
       "4  [1499348467.295837, 1499348467.296825, 1499348...              2   \n",
       "\n",
       "  fin_flag_count rst_flag_count  psh_flag_count ack_flag_count urg_flag_count  \\\n",
       "0              2              0               2             10              0   \n",
       "1              2              0               2              9              0   \n",
       "2              2              0               2              9              0   \n",
       "3              2              0               2             10              0   \n",
       "4              2              0               2              9              0   \n",
       "\n",
       "  cwr_flag_count ece_flag_count  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running sanity check to make sure there are no duplicates based on flow_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\"]\n",
    "duplicates = df.duplicated(subset=subset_cols)\n",
    "\n",
    "duplicate_rows = df[duplicates]\n",
    "assert duplicate_rows.shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any first_timestamp_fwd == -1\n",
    "first_fwd_timestamp = df[df.loc[:, \"first_timestamp_fwd\"] == -1]\n",
    "assert first_fwd_timestamp.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change to NaN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overall\n",
    "df[\"total_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "\n",
    "## Forward\n",
    "df[\"total_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "## Backward\n",
    "df[\"total_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.std(x)),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>total_bwd_pkt_size</th>\n",
       "      <th>avg_bwd_pkt_size</th>\n",
       "      <th>std_bwd_pkt_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_timestamp_bwd, last_timestamp_bwd, arrival_times_bwd, total_bwd_pkt_size, avg_bwd_pkt_size, std_bwd_pkt_size]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cases when first_timestamp_bwd == -1 => last_timestamp_bwd has to be -1 as well. Also, we should perhaps change total_bwd_pkt_size to NaN in this case too!\n",
    "first_bwd_timestamp = df[df.loc[:, \"first_timestamp_bwd\"] == -1]\n",
    "first_bwd_timestamp.loc[:, [\"first_timestamp_bwd\", \"last_timestamp_bwd\", \"arrival_times_bwd\", \"total_bwd_pkt_size\", \"avg_bwd_pkt_size\", \"std_bwd_pkt_size\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BWD timestamps conversion\n",
    "\n",
    "Convert -1 values to np.nan for better readability when converting to human-readable formats ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd_cols = [\"first_timestamp_bwd\", \"last_timestamp_bwd\"]\n",
    "df[bwd_cols] = df[bwd_cols].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport                  False\n",
       "src_ip                 False\n",
       "dst_port               False\n",
       "dst_ip                 False\n",
       "protocol               False\n",
       "sizes                  False\n",
       "first_timestamp        False\n",
       "last_timestamp         False\n",
       "flow_duration          False\n",
       "arrival_times          False\n",
       "total_fwd_packets      False\n",
       "fwd_pkt_sizes          False\n",
       "first_timestamp_fwd    False\n",
       "last_timestamp_fwd     False\n",
       "arrival_times_fwd      False\n",
       "total_bwd_packets      False\n",
       "bwd_pkt_sizes          False\n",
       "first_timestamp_bwd    False\n",
       "last_timestamp_bwd     False\n",
       "arrival_times_bwd      False\n",
       "syn_flag_count         False\n",
       "fin_flag_count         False\n",
       "rst_flag_count         False\n",
       "psh_flag_count         False\n",
       "ack_flag_count         False\n",
       "urg_flag_count         False\n",
       "cwr_flag_count         False\n",
       "ece_flag_count         False\n",
       "total_size             False\n",
       "avg_size               False\n",
       "std_size               False\n",
       "total_fwd_pkt_size     False\n",
       "avg_fwd_pkt_size       False\n",
       "std_fwd_pkt_size       False\n",
       "total_bwd_pkt_size     False\n",
       "avg_bwd_pkt_size       False\n",
       "std_bwd_pkt_size       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.eq(-1).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing flow durations\n",
    "\n",
    "NOTE: Flow durations are in SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499348407.419016</td>\n",
       "      <td>1499348412.425928</td>\n",
       "      <td>5.006912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499348413.192475</td>\n",
       "      <td>1499348418.262971</td>\n",
       "      <td>5.070496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499348422.024349</td>\n",
       "      <td>1499348427.063652</td>\n",
       "      <td>5.039303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1499348433.464668</td>\n",
       "      <td>1499348438.551871</td>\n",
       "      <td>5.087203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1499348467.295664</td>\n",
       "      <td>1499348472.302394</td>\n",
       "      <td>5.006730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1499348480.992304</td>\n",
       "      <td>1499348486.002003</td>\n",
       "      <td>5.009699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1499348494.345596</td>\n",
       "      <td>1499348499.355969</td>\n",
       "      <td>5.010373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1499348506.489087</td>\n",
       "      <td>1499348511.497289</td>\n",
       "      <td>5.008202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1499348514.064531</td>\n",
       "      <td>1499348519.077716</td>\n",
       "      <td>5.013185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1499348532.265347</td>\n",
       "      <td>1499348537.271470</td>\n",
       "      <td>5.006123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1499348565.285885</td>\n",
       "      <td>1499348570.303351</td>\n",
       "      <td>5.017466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1499348570.310628</td>\n",
       "      <td>1499348575.320284</td>\n",
       "      <td>5.009656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_timestamp     last_timestamp flow_duration\n",
       "0   1499348407.419016  1499348412.425928      5.006912\n",
       "1   1499348413.192475  1499348418.262971      5.070496\n",
       "2   1499348422.024349  1499348427.063652      5.039303\n",
       "3   1499348433.464668  1499348438.551871      5.087203\n",
       "4   1499348467.295664  1499348472.302394      5.006730\n",
       "5   1499348480.992304  1499348486.002003      5.009699\n",
       "6   1499348494.345596  1499348499.355969      5.010373\n",
       "7   1499348506.489087  1499348511.497289      5.008202\n",
       "8   1499348514.064531  1499348519.077716      5.013185\n",
       "9   1499348532.265347  1499348537.271470      5.006123\n",
       "10  1499348565.285885  1499348570.303351      5.017466\n",
       "11  1499348570.310628  1499348575.320284      5.009656"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fwd_flow_duration\"] = df.loc[:, \"last_timestamp_fwd\"] - df.loc[:, \"first_timestamp_fwd\"]\n",
    "df[\"bwd_flow_duration\"] = df.loc[:, \"last_timestamp_bwd\"] - df.loc[:, \"first_timestamp_bwd\"]\n",
    "df[\"flow_duration\"] = df.loc[:, \"last_timestamp\"] - df.loc[:, \"first_timestamp\"]\n",
    "df.loc[:, [\"first_timestamp\", \"last_timestamp\", \"flow_duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens to bwd_flow_duration when timestamps were -1.\n",
    "Sanity check to make sure it is also NaN to differentiate from case where there was exactly one bwd packet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[df.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, \"bwd_flow_duration\"].isna().all() == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: flow_duration will be 0 if only one packet was sent (overall, fwd or bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case when fwd_flow_duration is 0. total_fwd_packets should be 1 \n",
    "zero_fwd_flow_duration = df[df.loc[:, \"fwd_flow_duration\"] == 0]\n",
    "assert zero_fwd_flow_duration.shape[0] == zero_fwd_flow_duration.loc[:, \"total_fwd_packets\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are cases when flow_duration is > 0 but both bwd_flow_duration and fwd_flow_duration = 0. These are cases where at most one forward and backward packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_fwd_packets</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_flow_duration</th>\n",
       "      <th>bwd_flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [total_fwd_packets, total_bwd_packets, flow_duration, fwd_flow_duration, bwd_flow_duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for this case as well \n",
    "mismatched_durations = df[(df.loc[:, \"flow_duration\"] > 0) & (df.loc[:, \"fwd_flow_duration\"] == 0) & (df.loc[:, \"bwd_flow_duration\"] == 0)]\n",
    "mismatched_durations.loc[:, [\"total_fwd_packets\", \"total_bwd_packets\", \"flow_duration\", \"fwd_flow_duration\", \"bwd_flow_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make these assertions for checking\n",
    "if mismatched_durations.shape[0] > 0:\n",
    "    assert mismatched_durations.loc[:, \"total_fwd_packets\"].max() == 1\n",
    "    assert mismatched_durations.loc[:, \"total_bwd_packets\"].max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting timestamps to human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "\n",
    "# Overall\n",
    "df_test.loc[:, \"first_timestamp\"] = df.loc[:, \"first_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp\"] = df.loc[:, \"last_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Forward \n",
    "df_test.loc[:, \"first_timestamp_fwd\"] = df.loc[:, \"first_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp_fwd\"] = df.loc[:, \"last_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Backward \n",
    "df_test.loc[:, \"first_timestamp_bwd_new\"] = df.loc[:, \"first_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)\n",
    "df_test.loc[:, \"last_timestamp_bwd_new\"] = df.loc[:, \"last_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to make sure timestamp conversion preserves NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd_new</th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_timestamp_bwd_new, first_timestamp_bwd]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, [\"first_timestamp_bwd_new\", \"first_timestamp_bwd\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing inter-arrival times and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_time = df_test.copy()\n",
    "def find_diff(arrival_times):\n",
    "    return [float(arrival_times[i+1] - arrival_times[i]) for i in range(len(arrival_times)-1)]\n",
    "\n",
    "# Overall \n",
    "df_time.loc[:, \"inter_arrival_times\"] = df_time.loc[:, \"arrival_times\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean\"] = df_time.loc[:, \"inter_arrival_times\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std\"] = df_time.loc[: ,\"inter_arrival_times\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Forward\n",
    "df_time.loc[:, \"inter_arrival_times_fwd\"] = df_time.loc[:, \"arrival_times_fwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_fwd\"] = df_time.loc[:, \"inter_arrival_times_fwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_fwd\"] = df_time.loc[: ,\"inter_arrival_times_fwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Backward\n",
    "df_time.loc[:, \"inter_arrival_times_bwd\"] = df_time.loc[:, \"arrival_times_bwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_bwd\"] = df_time.loc[:, \"inter_arrival_times_bwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_bwd\"] = df_time.loc[: ,\"inter_arrival_times_bwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# df_time[df_time.loc[:, \"arrival_times\"].apply(lambda x: len(x) == 1)].loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>inter_arrival_times</th>\n",
       "      <th>inter_arrival_mean</th>\n",
       "      <th>inter_arrival_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1499348407.419016, 1499348407.419147, 1499348...</td>\n",
       "      <td>[0.000131, 0.001311, 4e-06, 9.2e-05, 0.003578,...</td>\n",
       "      <td>0.500691</td>\n",
       "      <td>1.499908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1499348413.192475, 1499348413.192603, 1499348...</td>\n",
       "      <td>[0.000128, 0.000773, 4e-06, 9.3e-05, 0.06727, ...</td>\n",
       "      <td>0.563388</td>\n",
       "      <td>1.569043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1499348422.024349, 1499348422.024463, 1499348...</td>\n",
       "      <td>[0.000114, 0.0008, 4e-06, 6.8e-05, 0.032476, 0...</td>\n",
       "      <td>0.559923</td>\n",
       "      <td>1.571372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1499348433.464668, 1499348433.464810, 1499348...</td>\n",
       "      <td>[0.000142, 0.000744, 4e-06, 9.9e-05, 0.080424,...</td>\n",
       "      <td>0.508720</td>\n",
       "      <td>1.498585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1499348467.295664, 1499348467.295837, 1499348...</td>\n",
       "      <td>[0.000173, 0.00055, 0.00033, 0.000108, 0.00428...</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>1.571102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1499348480.992304, 1499348480.992428, 1499348...</td>\n",
       "      <td>[0.000124, 0.000791, 4.9e-05, 4.3e-05, 0.00276...</td>\n",
       "      <td>0.556633</td>\n",
       "      <td>1.572624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1499348494.345596, 1499348494.345725, 1499348...</td>\n",
       "      <td>[0.000129, 0.000792, 4.9e-05, 4.8e-05, 0.0035,...</td>\n",
       "      <td>0.556708</td>\n",
       "      <td>1.572516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1499348506.489087, 1499348506.489193, 1499348...</td>\n",
       "      <td>[0.000106, 0.000808, 4e-06, 6.6e-05, 0.005116,...</td>\n",
       "      <td>0.556467</td>\n",
       "      <td>1.571265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1499348514.064531, 1499348514.064644, 1499348...</td>\n",
       "      <td>[0.000113, 0.000813, 3e-06, 6.4e-05, 0.010187,...</td>\n",
       "      <td>0.455744</td>\n",
       "      <td>1.437073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1499348532.265347, 1499348532.265484, 1499348...</td>\n",
       "      <td>[0.000137, 0.000775, 4e-06, 9.7e-05, 0.003553,...</td>\n",
       "      <td>0.556236</td>\n",
       "      <td>1.571159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1499348565.285885, 1499348565.286012, 1499348...</td>\n",
       "      <td>[0.000127, 0.000808, 4e-06, 0.000102, 0.010537...</td>\n",
       "      <td>0.456133</td>\n",
       "      <td>1.438180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1499348570.310628, 1499348570.310709, 1499348...</td>\n",
       "      <td>[8.1e-05, 0.000553, 0.000343, 5.6e-05, 0.00364...</td>\n",
       "      <td>0.556628</td>\n",
       "      <td>1.572315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        arrival_times  \\\n",
       "0   [1499348407.419016, 1499348407.419147, 1499348...   \n",
       "1   [1499348413.192475, 1499348413.192603, 1499348...   \n",
       "2   [1499348422.024349, 1499348422.024463, 1499348...   \n",
       "3   [1499348433.464668, 1499348433.464810, 1499348...   \n",
       "4   [1499348467.295664, 1499348467.295837, 1499348...   \n",
       "5   [1499348480.992304, 1499348480.992428, 1499348...   \n",
       "6   [1499348494.345596, 1499348494.345725, 1499348...   \n",
       "7   [1499348506.489087, 1499348506.489193, 1499348...   \n",
       "8   [1499348514.064531, 1499348514.064644, 1499348...   \n",
       "9   [1499348532.265347, 1499348532.265484, 1499348...   \n",
       "10  [1499348565.285885, 1499348565.286012, 1499348...   \n",
       "11  [1499348570.310628, 1499348570.310709, 1499348...   \n",
       "\n",
       "                                  inter_arrival_times  inter_arrival_mean  \\\n",
       "0   [0.000131, 0.001311, 4e-06, 9.2e-05, 0.003578,...            0.500691   \n",
       "1   [0.000128, 0.000773, 4e-06, 9.3e-05, 0.06727, ...            0.563388   \n",
       "2   [0.000114, 0.0008, 4e-06, 6.8e-05, 0.032476, 0...            0.559923   \n",
       "3   [0.000142, 0.000744, 4e-06, 9.9e-05, 0.080424,...            0.508720   \n",
       "4   [0.000173, 0.00055, 0.00033, 0.000108, 0.00428...            0.556303   \n",
       "5   [0.000124, 0.000791, 4.9e-05, 4.3e-05, 0.00276...            0.556633   \n",
       "6   [0.000129, 0.000792, 4.9e-05, 4.8e-05, 0.0035,...            0.556708   \n",
       "7   [0.000106, 0.000808, 4e-06, 6.6e-05, 0.005116,...            0.556467   \n",
       "8   [0.000113, 0.000813, 3e-06, 6.4e-05, 0.010187,...            0.455744   \n",
       "9   [0.000137, 0.000775, 4e-06, 9.7e-05, 0.003553,...            0.556236   \n",
       "10  [0.000127, 0.000808, 4e-06, 0.000102, 0.010537...            0.456133   \n",
       "11  [8.1e-05, 0.000553, 0.000343, 5.6e-05, 0.00364...            0.556628   \n",
       "\n",
       "    inter_arrival_std  \n",
       "0            1.499908  \n",
       "1            1.569043  \n",
       "2            1.571372  \n",
       "3            1.498585  \n",
       "4            1.571102  \n",
       "5            1.572624  \n",
       "6            1.572516  \n",
       "7            1.571265  \n",
       "8            1.437073  \n",
       "9            1.571159  \n",
       "10           1.438180  \n",
       "11           1.572315  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration',\n",
       "       'first_timestamp_bwd_new', 'last_timestamp_bwd_new',\n",
       "       'inter_arrival_times', 'inter_arrival_mean', 'inter_arrival_std',\n",
       "       'inter_arrival_times_fwd', 'inter_arrival_mean_fwd',\n",
       "       'inter_arrival_std_fwd', 'inter_arrival_times_bwd',\n",
       "       'inter_arrival_mean_bwd', 'inter_arrival_std_bwd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_features = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\", \"protocol\"]\n",
    "overall_features = [\"first_timestamp\", \"last_timestamp\", \"flow_duration\", \"total_size\", \"avg_size\", \"std_size\", \"inter_arrival_mean\", \"inter_arrival_std\"]\n",
    "fwd_features = [\"total_fwd_packets\", \"first_timestamp_fwd\", \"last_timestamp_fwd\", \"fwd_flow_duration\", \"total_fwd_pkt_size\", \"avg_fwd_pkt_size\", \"std_fwd_pkt_size\", \"inter_arrival_mean_fwd\", \"inter_arrival_std_fwd\"]\n",
    "bwd_features = ['total_bwd_packets', 'first_timestamp_bwd', 'last_timestamp_bwd', 'bwd_flow_duration', 'total_bwd_pkt_size', 'avg_bwd_pkt_size', 'std_bwd_pkt_size', 'inter_arrival_mean_bwd', 'inter_arrival_std_bwd']\n",
    "flag_features = ['syn_flag_count', 'fin_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count','cwr_flag_count', 'ece_flag_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features kept: 39\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = general_features + overall_features + fwd_features + bwd_features + flag_features\n",
    "print(f\"Total features kept: {len(features_to_keep)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching label for model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_time.copy()\n",
    "df_final = df_final[features_to_keep]\n",
    "df_final.loc[:, \"label\"] = \"webattack_sqli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"webattack_sqli.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
