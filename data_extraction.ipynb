{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scapy.all import * \n",
    "from datetime import datetime\n",
    "from datetime import UTC \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Main DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting TCP Flag Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Flags Mapping\n",
    "# Check here for bitmap: https://www.noction.com/blog/tcp-flags#:~:text=The%20hexadecimal%20number%200x02%20tells,a%20particular%20flag%20is%20set.\n",
    "FIN = 0x01\n",
    "SYN = 0x02\n",
    "RST = 0x04\n",
    "PSH = 0x08\n",
    "ACK = 0x10\n",
    "URG = 0x20\n",
    "ECE = 0x40\n",
    "CWR = 0x80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make important assumption that the first flow we see in the pcap for a unique flow_id, is considered as the \"forward packet\". This may not necessarily be the packet initiated by the host (perhaps), but it is a fair assumption to make. \n",
    "\n",
    "This assumption just helps us define a direction of the flow and should not change anything major. If any flow has a lot of packets being sent from one direction (think DDoS), then this imbalance will be captured in the fwd or bwd total packets column. (should not matter which one specifically) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(INPUT_FILE):\n",
    "\n",
    "    \"\"\"Finds all unique flows based on flow id. Returns data frame with basic metrics computed for each flow. \"\"\"\n",
    "    print(\"Reading .pcap file.\")\n",
    "    packets = rdpcap(INPUT_FILE)\n",
    "    print(\"Reading .pcap file DONE.\")\n",
    "\n",
    "\n",
    "    print(\"Creating initial dataframe.\")\n",
    "    all_data = {}\n",
    "    flow_fwd_states = []\n",
    "    i = 0\n",
    "    for pkt in packets:\n",
    "    \n",
    "        if IP in pkt:\n",
    "            tmp_pack_dict = {}\n",
    "\n",
    "            tmp_pack_dict[\"sport\"] = pkt[IP].sport if hasattr(pkt[IP], \"sport\") else None\n",
    "            tmp_pack_dict[\"src_ip\"] = pkt[IP].src \n",
    "            tmp_pack_dict[\"dst_port\"] = pkt[IP].dport if hasattr(pkt[IP], \"dport\") else None\n",
    "            tmp_pack_dict[\"dst_ip\"] = pkt[IP].dst\n",
    "            flow_size = pkt.len\n",
    "\n",
    "            # Check https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml for Assigned Internet Protocol Numbers\n",
    "            tmp_pack_dict['protocol'] = pkt.proto\n",
    "\n",
    "            # Flow Unique Identifier / Flow ID \n",
    "            flow_id = frozenset([tmp_pack_dict[\"sport\"], tmp_pack_dict[\"src_ip\"], tmp_pack_dict[\"dst_port\"], tmp_pack_dict[\"dst_ip\"]])\n",
    "            # Need set representation because if there is a backward flow (with just order changed of source and destination) then it should be marked as \"seen\" previously \n",
    "            # Ordered flow id (to check if belongs to the same stream or not)\n",
    "            flow_id_ordered = (tmp_pack_dict['sport'], tmp_pack_dict['src_ip'], tmp_pack_dict['dst_port'], tmp_pack_dict['dst_ip']) # save it in order\n",
    "\n",
    "            if flow_id not in all_data: #meaning this is a new flow (from a different stream) \n",
    "                tmp_pack_dict[\"sizes\"] = [flow_size]\n",
    "                tmp_pack_dict[\"first_timestamp\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp\"] = pkt.time \n",
    "                tmp_pack_dict[\"flow_duration\"] = 0 \n",
    "                tmp_pack_dict[\"arrival_times\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Forward packets \n",
    "                tmp_pack_dict[\"total_fwd_packets\"] = 1 # To count the first instance \n",
    "                tmp_pack_dict[\"fwd_pkt_sizes\"] = [pkt.len]\n",
    "                tmp_pack_dict[\"first_timestamp_fwd\"] = pkt.time\n",
    "                tmp_pack_dict[\"last_timestamp_fwd\"] = pkt.time \n",
    "                tmp_pack_dict[\"arrival_times_fwd\"] = [pkt.time]\n",
    "\n",
    "\n",
    "                # Backward packets \n",
    "                tmp_pack_dict[\"total_bwd_packets\"] = 0 \n",
    "                tmp_pack_dict[\"bwd_pkt_sizes\"] = [] \n",
    "                tmp_pack_dict[\"first_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"last_timestamp_bwd\"] = -1\n",
    "                tmp_pack_dict[\"arrival_times_bwd\"] = []\n",
    "\n",
    "                # Add flag counts \n",
    "                tmp_pack_dict[\"syn_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"fin_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"rst_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"psh_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ack_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"urg_flag_count\"] = 0 \n",
    "                tmp_pack_dict[\"cwr_flag_count\"] = 0\n",
    "                tmp_pack_dict[\"ece_flag_count\"] = 0\n",
    "\n",
    "                # create first time dictionary \n",
    "                all_data[flow_id] = tmp_pack_dict\n",
    "                # save the first instance of the flow as the forward trace \n",
    "                flow_fwd_states.append(flow_id_ordered)\n",
    "\n",
    "            else: # meaning either forward or backward trace (from the same flow!)\n",
    "\n",
    "                # Update the general features first \n",
    "                all_data[flow_id][\"sizes\"].append(flow_size) \n",
    "                all_data[flow_id][\"first_timestamp\"] = min(all_data[flow_id][\"first_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"last_timestamp\"] = max(all_data[flow_id][\"last_timestamp\"], pkt.time)\n",
    "                all_data[flow_id][\"flow_duration\"] = all_data[flow_id][\"last_timestamp\"] - all_data[flow_id][\"first_timestamp\"]\n",
    "                all_data[flow_id][\"arrival_times\"].append(pkt.time)\n",
    "                \n",
    "\n",
    "                # Add forward packet features \n",
    "                if flow_id_ordered in flow_fwd_states: # check if forward packet and not backward \n",
    "                    all_data[flow_id][\"total_fwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"fwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_fwd\"] = min(all_data[flow_id][\"first_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_fwd\"] = max(all_data[flow_id][\"last_timestamp_fwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_fwd\"].append(pkt.time)\n",
    "\n",
    "                else:\n",
    "                    all_data[flow_id][\"total_bwd_packets\"] += 1 \n",
    "                    all_data[flow_id][\"bwd_pkt_sizes\"].append(pkt.len) \n",
    "                    all_data[flow_id][\"first_timestamp_bwd\"] = pkt.time if all_data[flow_id][\"first_timestamp_bwd\"] == -1 else min(all_data[flow_id][\"first_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"last_timestamp_bwd\"] = max(all_data[flow_id][\"last_timestamp_bwd\"], pkt.time)\n",
    "                    all_data[flow_id][\"arrival_times_bwd\"].append(pkt.time)\n",
    "\n",
    "            if TCP in pkt[IP]:\n",
    "                all_data[flow_id][\"syn_flag_count\"] += 1 if pkt[IP][TCP].flags & SYN else 0 \n",
    "                all_data[flow_id][\"fin_flag_count\"] += 1 if pkt[IP][TCP].flags & FIN else 0\n",
    "                all_data[flow_id][\"rst_flag_count\"] += 1 if pkt[IP][TCP].flags & RST else 0 \n",
    "                all_data[flow_id][\"psh_flag_count\"] += 1 if pkt[IP][TCP].flags & PSH else 0\n",
    "                all_data[flow_id][\"ack_flag_count\"] += 1 if pkt[IP][TCP].flags & ACK else 0 \n",
    "                all_data[flow_id][\"urg_flag_count\"] += 1 if pkt[IP][TCP].flags & URG else 0 \n",
    "                all_data[flow_id][\"cwr_flag_count\"] += 1 if pkt[IP][TCP].flags & CWR else 0\n",
    "                all_data[flow_id][\"ece_flag_count\"] += 1 if pkt[IP][TCP].flags & ECE else 0\n",
    "                \n",
    "\n",
    "    df = pd.DataFrame.from_dict(all_data, orient=\"index\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"Initial data frame created.\")\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .pcap file.\n",
      "Reading .pcap file DONE.\n",
      "Creating initial dataframe.\n",
      "Initial data frame created.\n"
     ]
    }
   ],
   "source": [
    "FILE = \"Port_Scan_10per_streams.pcap\"\n",
    "df = create_dataframe(INPUT_FILE=FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>protocol</th>\n",
       "      <th>sizes</th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>...</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>syn_flag_count</th>\n",
       "      <th>fin_flag_count</th>\n",
       "      <th>rst_flag_count</th>\n",
       "      <th>psh_flag_count</th>\n",
       "      <th>ack_flag_count</th>\n",
       "      <th>urg_flag_count</th>\n",
       "      <th>cwr_flag_count</th>\n",
       "      <th>ece_flag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40556</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[60, 60, 52, 399, 52, 416, 52, 408, 1100, 52, ...</td>\n",
       "      <td>1499441877.184978</td>\n",
       "      <td>1499441882.213039</td>\n",
       "      <td>5.028061</td>\n",
       "      <td>[1499441877.184978, 1499441877.185112, 1499441...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499441882.213039</td>\n",
       "      <td>[1499441877.185112, 1499441877.186098, 1499441...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55000</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[44, 40]</td>\n",
       "      <td>1499446536.020843</td>\n",
       "      <td>1499446536.020932</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>[1499446536.020843, 1499446536.020932]</td>\n",
       "      <td>...</td>\n",
       "      <td>1499446536.020932</td>\n",
       "      <td>[1499446536.020932]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63214</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>21</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[44, 44, 40]</td>\n",
       "      <td>1499446540.456491</td>\n",
       "      <td>1499446540.457139</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>[1499446540.456491, 1499446540.45656, 14994465...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499446540.45656</td>\n",
       "      <td>[1499446540.45656]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63214</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>444</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[44, 40]</td>\n",
       "      <td>1499446540.863161</td>\n",
       "      <td>1499446540.863282</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>[1499446540.863161, 1499446540.863282]</td>\n",
       "      <td>...</td>\n",
       "      <td>1499446540.863282</td>\n",
       "      <td>[1499446540.863282]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38040</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>[44, 44, 40]</td>\n",
       "      <td>1499446552.413619</td>\n",
       "      <td>1499446552.414284</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>[1499446552.413619, 1499446552.413746, 1499446...</td>\n",
       "      <td>...</td>\n",
       "      <td>1499446552.413746</td>\n",
       "      <td>[1499446552.413746]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sport      src_ip  dst_port         dst_ip  protocol  \\\n",
       "0  40556  172.16.0.1        80  192.168.10.50         6   \n",
       "1  55000  172.16.0.1       443  192.168.10.50         6   \n",
       "2  63214  172.16.0.1        21  192.168.10.50         6   \n",
       "3  63214  172.16.0.1       444  192.168.10.50         6   \n",
       "4  38040  172.16.0.1        80  192.168.10.50         6   \n",
       "\n",
       "                                               sizes    first_timestamp  \\\n",
       "0  [60, 60, 52, 399, 52, 416, 52, 408, 1100, 52, ...  1499441877.184978   \n",
       "1                                           [44, 40]  1499446536.020843   \n",
       "2                                       [44, 44, 40]  1499446540.456491   \n",
       "3                                           [44, 40]  1499446540.863161   \n",
       "4                                       [44, 44, 40]  1499446552.413619   \n",
       "\n",
       "      last_timestamp flow_duration  \\\n",
       "0  1499441882.213039      5.028061   \n",
       "1  1499446536.020932      0.000089   \n",
       "2  1499446540.457139      0.000648   \n",
       "3  1499446540.863282      0.000121   \n",
       "4  1499446552.414284      0.000665   \n",
       "\n",
       "                                       arrival_times  ...  last_timestamp_bwd  \\\n",
       "0  [1499441877.184978, 1499441877.185112, 1499441...  ...   1499441882.213039   \n",
       "1             [1499446536.020843, 1499446536.020932]  ...   1499446536.020932   \n",
       "2  [1499446540.456491, 1499446540.45656, 14994465...  ...    1499446540.45656   \n",
       "3             [1499446540.863161, 1499446540.863282]  ...   1499446540.863282   \n",
       "4  [1499446552.413619, 1499446552.413746, 1499446...  ...   1499446552.413746   \n",
       "\n",
       "                                   arrival_times_bwd syn_flag_count  \\\n",
       "0  [1499441877.185112, 1499441877.186098, 1499441...              2   \n",
       "1                                [1499446536.020932]              1   \n",
       "2                                 [1499446540.45656]              2   \n",
       "3                                [1499446540.863282]              1   \n",
       "4                                [1499446552.413746]              2   \n",
       "\n",
       "  fin_flag_count rst_flag_count  psh_flag_count ack_flag_count urg_flag_count  \\\n",
       "0              2              0               4             12              0   \n",
       "1              0              1               0              1              0   \n",
       "2              0              1               0              1              0   \n",
       "3              0              1               0              1              0   \n",
       "4              0              1               0              1              0   \n",
       "\n",
       "  cwr_flag_count ece_flag_count  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running sanity check to make sure there are no duplicates based on flow_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\"]\n",
    "duplicates = df.duplicated(subset=subset_cols)\n",
    "\n",
    "duplicate_rows = df[duplicates]\n",
    "assert duplicate_rows.shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any first_timestamp_fwd == -1\n",
    "first_fwd_timestamp = df[df.loc[:, \"first_timestamp_fwd\"] == -1]\n",
    "assert first_fwd_timestamp.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change to NaN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "## Overall\n",
    "df[\"total_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_size\"] = round(df.loc[:, \"sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "\n",
    "## Forward\n",
    "df[\"total_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_fwd_pkt_size\"] = round(df.loc[:, \"fwd_pkt_sizes\"].apply(lambda x: np.std(x)), 3)\n",
    "## Backward\n",
    "df[\"total_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.sum(x)), 3)\n",
    "df[\"avg_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.mean(x)), 3)\n",
    "df[\"std_bwd_pkt_size\"] = round(df.loc[:, \"bwd_pkt_sizes\"].apply(lambda x: np.std(x)),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "      <th>last_timestamp_bwd</th>\n",
       "      <th>arrival_times_bwd</th>\n",
       "      <th>total_bwd_pkt_size</th>\n",
       "      <th>avg_bwd_pkt_size</th>\n",
       "      <th>std_bwd_pkt_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15166</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15167</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15169</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15175</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15176</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15177</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15178</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15179</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15180</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15181</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15182</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15183</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15184</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15185</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15186</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15187</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15188</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15191</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15199</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15203</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_timestamp_bwd last_timestamp_bwd arrival_times_bwd  \\\n",
       "15166                  -1                 -1                []   \n",
       "15167                  -1                 -1                []   \n",
       "15168                  -1                 -1                []   \n",
       "15169                  -1                 -1                []   \n",
       "15170                  -1                 -1                []   \n",
       "15171                  -1                 -1                []   \n",
       "15172                  -1                 -1                []   \n",
       "15173                  -1                 -1                []   \n",
       "15174                  -1                 -1                []   \n",
       "15175                  -1                 -1                []   \n",
       "15176                  -1                 -1                []   \n",
       "15177                  -1                 -1                []   \n",
       "15178                  -1                 -1                []   \n",
       "15179                  -1                 -1                []   \n",
       "15180                  -1                 -1                []   \n",
       "15181                  -1                 -1                []   \n",
       "15182                  -1                 -1                []   \n",
       "15183                  -1                 -1                []   \n",
       "15184                  -1                 -1                []   \n",
       "15185                  -1                 -1                []   \n",
       "15186                  -1                 -1                []   \n",
       "15187                  -1                 -1                []   \n",
       "15188                  -1                 -1                []   \n",
       "15191                  -1                 -1                []   \n",
       "15196                  -1                 -1                []   \n",
       "15199                  -1                 -1                []   \n",
       "15203                  -1                 -1                []   \n",
       "\n",
       "       total_bwd_pkt_size  avg_bwd_pkt_size  std_bwd_pkt_size  \n",
       "15166                 0.0               NaN               NaN  \n",
       "15167                 0.0               NaN               NaN  \n",
       "15168                 0.0               NaN               NaN  \n",
       "15169                 0.0               NaN               NaN  \n",
       "15170                 0.0               NaN               NaN  \n",
       "15171                 0.0               NaN               NaN  \n",
       "15172                 0.0               NaN               NaN  \n",
       "15173                 0.0               NaN               NaN  \n",
       "15174                 0.0               NaN               NaN  \n",
       "15175                 0.0               NaN               NaN  \n",
       "15176                 0.0               NaN               NaN  \n",
       "15177                 0.0               NaN               NaN  \n",
       "15178                 0.0               NaN               NaN  \n",
       "15179                 0.0               NaN               NaN  \n",
       "15180                 0.0               NaN               NaN  \n",
       "15181                 0.0               NaN               NaN  \n",
       "15182                 0.0               NaN               NaN  \n",
       "15183                 0.0               NaN               NaN  \n",
       "15184                 0.0               NaN               NaN  \n",
       "15185                 0.0               NaN               NaN  \n",
       "15186                 0.0               NaN               NaN  \n",
       "15187                 0.0               NaN               NaN  \n",
       "15188                 0.0               NaN               NaN  \n",
       "15191                 0.0               NaN               NaN  \n",
       "15196                 0.0               NaN               NaN  \n",
       "15199                 0.0               NaN               NaN  \n",
       "15203                 0.0               NaN               NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cases when first_timestamp_bwd == -1 => last_timestamp_bwd has to be -1 as well. Also, we should perhaps change total_bwd_pkt_size to NaN in this case too!\n",
    "first_bwd_timestamp = df[df.loc[:, \"first_timestamp_bwd\"] == -1]\n",
    "first_bwd_timestamp.loc[:, [\"first_timestamp_bwd\", \"last_timestamp_bwd\", \"arrival_times_bwd\", \"total_bwd_pkt_size\", \"avg_bwd_pkt_size\", \"std_bwd_pkt_size\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BWD timestamps conversion\n",
    "\n",
    "Convert -1 values to np.nan for better readability when converting to human-readable formats ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd_cols = [\"first_timestamp_bwd\", \"last_timestamp_bwd\"]\n",
    "df[bwd_cols] = df[bwd_cols].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport                  False\n",
       "src_ip                 False\n",
       "dst_port               False\n",
       "dst_ip                 False\n",
       "protocol               False\n",
       "sizes                  False\n",
       "first_timestamp        False\n",
       "last_timestamp         False\n",
       "flow_duration          False\n",
       "arrival_times          False\n",
       "total_fwd_packets      False\n",
       "fwd_pkt_sizes          False\n",
       "first_timestamp_fwd    False\n",
       "last_timestamp_fwd     False\n",
       "arrival_times_fwd      False\n",
       "total_bwd_packets      False\n",
       "bwd_pkt_sizes          False\n",
       "first_timestamp_bwd    False\n",
       "last_timestamp_bwd     False\n",
       "arrival_times_bwd      False\n",
       "syn_flag_count         False\n",
       "fin_flag_count         False\n",
       "rst_flag_count         False\n",
       "psh_flag_count         False\n",
       "ack_flag_count         False\n",
       "urg_flag_count         False\n",
       "cwr_flag_count         False\n",
       "ece_flag_count         False\n",
       "total_size             False\n",
       "avg_size               False\n",
       "std_size               False\n",
       "total_fwd_pkt_size     False\n",
       "avg_fwd_pkt_size       False\n",
       "std_fwd_pkt_size       False\n",
       "total_bwd_pkt_size     False\n",
       "avg_bwd_pkt_size       False\n",
       "std_bwd_pkt_size       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.eq(-1).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing flow durations\n",
    "\n",
    "NOTE: Flow durations are in SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp</th>\n",
       "      <th>last_timestamp</th>\n",
       "      <th>flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499441877.184978</td>\n",
       "      <td>1499441882.213039</td>\n",
       "      <td>5.028061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499446536.020843</td>\n",
       "      <td>1499446536.020932</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499446540.456491</td>\n",
       "      <td>1499446540.457139</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1499446540.863161</td>\n",
       "      <td>1499446540.863282</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1499446552.413619</td>\n",
       "      <td>1499446552.414284</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16085</th>\n",
       "      <td>1499451832.021263</td>\n",
       "      <td>1499451832.021281</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>1499451832.021495</td>\n",
       "      <td>1499451832.021539</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16087</th>\n",
       "      <td>1499451832.021606</td>\n",
       "      <td>1499451832.021649</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16088</th>\n",
       "      <td>1499451832.021759</td>\n",
       "      <td>1499451832.021813</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>1499451832.026762</td>\n",
       "      <td>1499451832.026797</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16090 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         first_timestamp     last_timestamp flow_duration\n",
       "0      1499441877.184978  1499441882.213039      5.028061\n",
       "1      1499446536.020843  1499446536.020932      0.000089\n",
       "2      1499446540.456491  1499446540.457139      0.000648\n",
       "3      1499446540.863161  1499446540.863282      0.000121\n",
       "4      1499446552.413619  1499446552.414284      0.000665\n",
       "...                  ...                ...           ...\n",
       "16085  1499451832.021263  1499451832.021281      0.000018\n",
       "16086  1499451832.021495  1499451832.021539      0.000044\n",
       "16087  1499451832.021606  1499451832.021649      0.000043\n",
       "16088  1499451832.021759  1499451832.021813      0.000054\n",
       "16089  1499451832.026762  1499451832.026797      0.000035\n",
       "\n",
       "[16090 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fwd_flow_duration\"] = df.loc[:, \"last_timestamp_fwd\"] - df.loc[:, \"first_timestamp_fwd\"]\n",
    "df[\"bwd_flow_duration\"] = df.loc[:, \"last_timestamp_bwd\"] - df.loc[:, \"first_timestamp_bwd\"]\n",
    "df[\"flow_duration\"] = df.loc[:, \"last_timestamp\"] - df.loc[:, \"first_timestamp\"]\n",
    "df.loc[:, [\"first_timestamp\", \"last_timestamp\", \"flow_duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens to bwd_flow_duration when timestamps were -1.\n",
    "Sanity check to make sure it is also NaN to differentiate from case where there was exactly one bwd packet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[df.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, \"bwd_flow_duration\"].isna().all() == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: flow_duration will be 0 if only one packet was sent (overall, fwd or bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case when fwd_flow_duration is 0. total_fwd_packets should be 1 \n",
    "zero_fwd_flow_duration = df[df.loc[:, \"fwd_flow_duration\"] == 0]\n",
    "assert zero_fwd_flow_duration.shape[0] == zero_fwd_flow_duration.loc[:, \"total_fwd_packets\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are cases when flow_duration is > 0 but both bwd_flow_duration and fwd_flow_duration = 0. These are cases where at most one forward and backward packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_fwd_packets</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_flow_duration</th>\n",
       "      <th>bwd_flow_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [total_fwd_packets, total_bwd_packets, flow_duration, fwd_flow_duration, bwd_flow_duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for this case as well \n",
    "mismatched_durations = df[(df.loc[:, \"flow_duration\"] > 0) & (df.loc[:, \"fwd_flow_duration\"] == 0) & (df.loc[:, \"bwd_flow_duration\"] == 0)]\n",
    "mismatched_durations.loc[:, [\"total_fwd_packets\", \"total_bwd_packets\", \"flow_duration\", \"fwd_flow_duration\", \"bwd_flow_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make these assertions for checking\n",
    "if mismatched_durations.shape[0] > 0:\n",
    "    assert mismatched_durations.loc[:, \"total_fwd_packets\"].max() == 1\n",
    "    assert mismatched_durations.loc[:, \"total_bwd_packets\"].max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting timestamps to human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "\n",
    "# Overall\n",
    "df_test.loc[:, \"first_timestamp\"] = df.loc[:, \"first_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp\"] = df.loc[:, \"last_timestamp\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Forward \n",
    "df_test.loc[:, \"first_timestamp_fwd\"] = df.loc[:, \"first_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df_test.loc[:, \"last_timestamp_fwd\"] = df.loc[:, \"last_timestamp_fwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "# Backward \n",
    "df_test.loc[:, \"first_timestamp_bwd_new\"] = df.loc[:, \"first_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)\n",
    "df_test.loc[:, \"last_timestamp_bwd_new\"] = df.loc[:, \"last_timestamp_bwd\"].apply(lambda x: datetime.fromtimestamp(float(x), UTC).strftime(\"%Y-%m-%d %H:%M:%S.%f\") if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to make sure timestamp conversion preserves NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_timestamp_bwd_new</th>\n",
       "      <th>first_timestamp_bwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_timestamp_bwd_new first_timestamp_bwd\n",
       "3284                     NaN                 NaN\n",
       "4411                     NaN                 NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.loc[:, \"first_timestamp_bwd\"].isna()].loc[:, [\"first_timestamp_bwd_new\", \"first_timestamp_bwd\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing inter-arrival times and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_time = df_test.copy()\n",
    "def find_diff(arrival_times):\n",
    "    return [float(arrival_times[i+1] - arrival_times[i]) for i in range(len(arrival_times)-1)]\n",
    "\n",
    "# Overall \n",
    "df_time.loc[:, \"inter_arrival_times\"] = df_time.loc[:, \"arrival_times\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean\"] = df_time.loc[:, \"inter_arrival_times\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std\"] = df_time.loc[: ,\"inter_arrival_times\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Forward\n",
    "df_time.loc[:, \"inter_arrival_times_fwd\"] = df_time.loc[:, \"arrival_times_fwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_fwd\"] = df_time.loc[:, \"inter_arrival_times_fwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_fwd\"] = df_time.loc[: ,\"inter_arrival_times_fwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# Backward\n",
    "df_time.loc[:, \"inter_arrival_times_bwd\"] = df_time.loc[:, \"arrival_times_bwd\"].apply(find_diff)\n",
    "df_time.loc[:, \"inter_arrival_mean_bwd\"] = df_time.loc[:, \"inter_arrival_times_bwd\"].apply(lambda x: np.mean(x))\n",
    "df_time.loc[:, \"inter_arrival_std_bwd\"] = df_time.loc[: ,\"inter_arrival_times_bwd\"].apply(lambda x: np.std(x))\n",
    "\n",
    "# df_time[df_time.loc[:, \"arrival_times\"].apply(lambda x: len(x) == 1)].loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_times</th>\n",
       "      <th>inter_arrival_times</th>\n",
       "      <th>inter_arrival_mean</th>\n",
       "      <th>inter_arrival_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1499453793.83595, 1499453793.836082, 14994537...</td>\n",
       "      <td>[0.000132, 0.000888, 4.9e-05, 7.9e-05, 0.01433...</td>\n",
       "      <td>0.702354</td>\n",
       "      <td>2.324233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1499453793.850928, 1499453793.851047, 1499453...</td>\n",
       "      <td>[0.000119, 0.000849, 4.8e-05, 8.9e-05, 0.00844...</td>\n",
       "      <td>22.735791</td>\n",
       "      <td>112.563018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1499453793.875876, 1499453793.876012, 1499453...</td>\n",
       "      <td>[0.000136, 0.000857, 4.8e-05, 6.4e-05, 1.6548,...</td>\n",
       "      <td>21.133950</td>\n",
       "      <td>101.011109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1499453796.193416, 1499453796.193514, 1499453...</td>\n",
       "      <td>[9.8e-05, 0.000612, 1.8e-05, 5.9e-05, 1.344956...</td>\n",
       "      <td>0.570284</td>\n",
       "      <td>1.626237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1499453797.195724, 1499453797.195832, 1499453...</td>\n",
       "      <td>[0.000108, 0.000704, 4e-06, 6e-05, 0.655491, 5...</td>\n",
       "      <td>0.493280</td>\n",
       "      <td>1.528730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8578</th>\n",
       "      <td>[1499454970.599251, 1499454970.599333, 1499454...</td>\n",
       "      <td>[8.2e-05, 0.00074, 0.000361, 0.000146, 0.00110...</td>\n",
       "      <td>0.145719</td>\n",
       "      <td>0.455978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>[1499454970.614938, 1499454970.614986, 1499454...</td>\n",
       "      <td>[4.8e-05, 0.000503, 0.00171, 0.00018, 0.000257...</td>\n",
       "      <td>0.132185</td>\n",
       "      <td>0.435178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>[1499454970.630293, 1499454970.630338, 1499454...</td>\n",
       "      <td>[4.5e-05, 0.000719, 0.000262, 6.3e-05, 1.56841...</td>\n",
       "      <td>0.224838</td>\n",
       "      <td>0.548513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>[1499454970.630335, 1499454970.630523, 1499454...</td>\n",
       "      <td>[0.000188, 0.00062, 0.000198, 6.6e-05, 1.56843...</td>\n",
       "      <td>0.143255</td>\n",
       "      <td>0.450682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>[1499454970.630778, 1499454970.630819, 1499454...</td>\n",
       "      <td>[4.1e-05, 0.000753, 0.000167, 0.000119, 1.567493]</td>\n",
       "      <td>0.313715</td>\n",
       "      <td>0.626889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8583 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          arrival_times  \\\n",
       "0     [1499453793.83595, 1499453793.836082, 14994537...   \n",
       "1     [1499453793.850928, 1499453793.851047, 1499453...   \n",
       "2     [1499453793.875876, 1499453793.876012, 1499453...   \n",
       "3     [1499453796.193416, 1499453796.193514, 1499453...   \n",
       "4     [1499453797.195724, 1499453797.195832, 1499453...   \n",
       "...                                                 ...   \n",
       "8578  [1499454970.599251, 1499454970.599333, 1499454...   \n",
       "8579  [1499454970.614938, 1499454970.614986, 1499454...   \n",
       "8580  [1499454970.630293, 1499454970.630338, 1499454...   \n",
       "8581  [1499454970.630335, 1499454970.630523, 1499454...   \n",
       "8582  [1499454970.630778, 1499454970.630819, 1499454...   \n",
       "\n",
       "                                    inter_arrival_times  inter_arrival_mean  \\\n",
       "0     [0.000132, 0.000888, 4.9e-05, 7.9e-05, 0.01433...            0.702354   \n",
       "1     [0.000119, 0.000849, 4.8e-05, 8.9e-05, 0.00844...           22.735791   \n",
       "2     [0.000136, 0.000857, 4.8e-05, 6.4e-05, 1.6548,...           21.133950   \n",
       "3     [9.8e-05, 0.000612, 1.8e-05, 5.9e-05, 1.344956...            0.570284   \n",
       "4     [0.000108, 0.000704, 4e-06, 6e-05, 0.655491, 5...            0.493280   \n",
       "...                                                 ...                 ...   \n",
       "8578  [8.2e-05, 0.00074, 0.000361, 0.000146, 0.00110...            0.145719   \n",
       "8579  [4.8e-05, 0.000503, 0.00171, 0.00018, 0.000257...            0.132185   \n",
       "8580  [4.5e-05, 0.000719, 0.000262, 6.3e-05, 1.56841...            0.224838   \n",
       "8581  [0.000188, 0.00062, 0.000198, 6.6e-05, 1.56843...            0.143255   \n",
       "8582  [4.1e-05, 0.000753, 0.000167, 0.000119, 1.567493]            0.313715   \n",
       "\n",
       "      inter_arrival_std  \n",
       "0              2.324233  \n",
       "1            112.563018  \n",
       "2            101.011109  \n",
       "3              1.626237  \n",
       "4              1.528730  \n",
       "...                 ...  \n",
       "8578           0.455978  \n",
       "8579           0.435178  \n",
       "8580           0.548513  \n",
       "8581           0.450682  \n",
       "8582           0.626889  \n",
       "\n",
       "[8583 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.loc[:, [\"arrival_times\", \"inter_arrival_times\", \"inter_arrival_mean\", \"inter_arrival_std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sport', 'src_ip', 'dst_port', 'dst_ip', 'protocol', 'sizes',\n",
       "       'first_timestamp', 'last_timestamp', 'flow_duration', 'arrival_times',\n",
       "       'total_fwd_packets', 'fwd_pkt_sizes', 'first_timestamp_fwd',\n",
       "       'last_timestamp_fwd', 'arrival_times_fwd', 'total_bwd_packets',\n",
       "       'bwd_pkt_sizes', 'first_timestamp_bwd', 'last_timestamp_bwd',\n",
       "       'arrival_times_bwd', 'syn_flag_count', 'fin_flag_count',\n",
       "       'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count',\n",
       "       'cwr_flag_count', 'ece_flag_count', 'total_size', 'avg_size',\n",
       "       'std_size', 'total_fwd_pkt_size', 'avg_fwd_pkt_size',\n",
       "       'std_fwd_pkt_size', 'total_bwd_pkt_size', 'avg_bwd_pkt_size',\n",
       "       'std_bwd_pkt_size', 'fwd_flow_duration', 'bwd_flow_duration',\n",
       "       'first_timestamp_bwd_new', 'last_timestamp_bwd_new',\n",
       "       'inter_arrival_times', 'inter_arrival_mean', 'inter_arrival_std',\n",
       "       'inter_arrival_times_fwd', 'inter_arrival_mean_fwd',\n",
       "       'inter_arrival_std_fwd', 'inter_arrival_times_bwd',\n",
       "       'inter_arrival_mean_bwd', 'inter_arrival_std_bwd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_features = [\"sport\", \"src_ip\", \"dst_port\", \"dst_ip\", \"protocol\"]\n",
    "overall_features = [\"first_timestamp\", \"last_timestamp\", \"flow_duration\", \"total_size\", \"avg_size\", \"std_size\", \"inter_arrival_mean\", \"inter_arrival_std\"]\n",
    "fwd_features = [\"total_fwd_packets\", \"first_timestamp_fwd\", \"last_timestamp_fwd\", \"fwd_flow_duration\", \"total_fwd_pkt_size\", \"avg_fwd_pkt_size\", \"std_fwd_pkt_size\", \"inter_arrival_mean_fwd\", \"inter_arrival_std_fwd\"]\n",
    "bwd_features = ['total_bwd_packets', 'first_timestamp_bwd', 'last_timestamp_bwd', 'bwd_flow_duration', 'total_bwd_pkt_size', 'avg_bwd_pkt_size', 'std_bwd_pkt_size', 'inter_arrival_mean_bwd', 'inter_arrival_std_bwd']\n",
    "flag_features = ['syn_flag_count', 'fin_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count', 'urg_flag_count','cwr_flag_count', 'ece_flag_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features kept: 39\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = general_features + overall_features + fwd_features + bwd_features + flag_features\n",
    "print(f\"Total features kept: {len(features_to_keep)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching label for model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_time.copy()\n",
    "df_final = df_final[features_to_keep]\n",
    "df_final.loc[:, \"label\"] = \"port_scan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"port_scan_check.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
